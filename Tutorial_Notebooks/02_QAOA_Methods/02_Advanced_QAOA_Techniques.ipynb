{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "92dc600e",
   "metadata": {},
   "source": [
    "# Advanced QAOA Techniques\n",
    "\n",
    "## Learning Objectives\n",
    "- Implement Recursive QAOA (RQAOA) for improved performance\n",
    "- Learn Multi-Angle QAOA for better parameter optimization\n",
    "- Understand warm-starting techniques\n",
    "- Explore hardware-efficient QAOA variants\n",
    "- Compare advanced methods on challenging problems\n",
    "\n",
    "## Why Advanced QAOA?\n",
    "\n",
    "Standard QAOA faces several challenges:\n",
    "1. **Parameter optimization**: Exponentially hard landscape\n",
    "2. **Circuit depth limitations**: NISQ device constraints\n",
    "3. **Barren plateaus**: Gradients vanish for large systems\n",
    "4. **Problem-specific performance**: No universal parameters\n",
    "\n",
    "Advanced techniques address these limitations through:\n",
    "- **Recursive approaches**: Break problems into smaller pieces\n",
    "- **Adaptive parameters**: Learn from problem structure\n",
    "- **Warm-starting**: Use classical solutions as initialization\n",
    "- **Hardware optimization**: Reduce circuit complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fe593e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "import itertools\n",
    "from dataclasses import dataclass\n",
    "from scipy.optimize import minimize\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import time\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Advanced QAOA Tutorial Environment Ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ae9fb8e",
   "metadata": {},
   "source": [
    "## 1. Recursive QAOA (RQAOA)\n",
    "\n",
    "RQAOA iteratively fixes variables and reduces problem size:\n",
    "\n",
    "1. **Run QAOA** on full problem\n",
    "2. **Identify confident bits** (high probability)\n",
    "3. **Fix these variables** to their most likely values\n",
    "4. **Create reduced problem** with fewer variables\n",
    "5. **Repeat** until problem is small enough\n",
    "\n",
    "**Benefits**:\n",
    "- Reduces circuit depth requirements\n",
    "- Often finds better solutions than standard QAOA\n",
    "- Natural divide-and-conquer approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc0579b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, let's import our basic QAOA implementation from the previous notebook\n",
    "\n",
    "class QuantumState:\n",
    "    \"\"\"Quantum state representation for simulation\"\"\"\n",
    "    \n",
    "    def __init__(self, n_qubits: int):\n",
    "        self.n_qubits = n_qubits\n",
    "        self.n_states = 2**n_qubits\n",
    "        # Initialize in uniform superposition |+>\n",
    "        self.amplitudes = np.ones(self.n_states, dtype=complex) / np.sqrt(self.n_states)\n",
    "    \n",
    "    def apply_phase_gate(self, qubit_idx: int, phase: float):\n",
    "        \"\"\"Apply phase gate to specific qubit\"\"\"\n",
    "        for state in range(self.n_states):\n",
    "            if (state >> qubit_idx) & 1:  # If qubit is |1>\n",
    "                self.amplitudes[state] *= np.exp(1j * phase)\n",
    "    \n",
    "    def apply_mixer(self, angle: float):\n",
    "        \"\"\"Apply mixer Hamiltonian (X rotations on all qubits)\"\"\"\n",
    "        new_amplitudes = np.zeros_like(self.amplitudes)\n",
    "        cos_half = np.cos(angle / 2)\n",
    "        sin_half = -1j * np.sin(angle / 2)\n",
    "        \n",
    "        for state in range(self.n_states):\n",
    "            # Apply X rotation to each qubit\n",
    "            for qubit in range(self.n_qubits):\n",
    "                flipped_state = state ^ (1 << qubit)\n",
    "                new_amplitudes[state] += cos_half * self.amplitudes[state]\n",
    "                new_amplitudes[flipped_state] += sin_half * self.amplitudes[state]\n",
    "        \n",
    "        # Normalize after applying to all qubits\n",
    "        self.amplitudes = new_amplitudes / np.sqrt(self.n_qubits)\n",
    "    \n",
    "    def get_probabilities(self) -> np.ndarray:\n",
    "        \"\"\"Get measurement probabilities\"\"\"\n",
    "        return np.abs(self.amplitudes)**2\n",
    "    \n",
    "    def sample(self, n_shots: int = 1000) -> List[int]:\n",
    "        \"\"\"Sample from the quantum state\"\"\"\n",
    "        probabilities = self.get_probabilities()\n",
    "        return np.random.choice(self.n_states, size=n_shots, p=probabilities)\n",
    "\n",
    "class BasicQAOA:\n",
    "    \"\"\"Basic QAOA implementation for comparison\"\"\"\n",
    "    \n",
    "    def __init__(self, cost_hamiltonian: Callable[[int], float]):\n",
    "        self.cost_hamiltonian = cost_hamiltonian\n",
    "    \n",
    "    def run_circuit(self, gammas: List[float], betas: List[float], \n",
    "                   n_qubits: int) -> QuantumState:\n",
    "        \"\"\"Run QAOA circuit\"\"\"\n",
    "        state = QuantumState(n_qubits)\n",
    "        \n",
    "        # Apply QAOA layers\n",
    "        for gamma, beta in zip(gammas, betas):\n",
    "            # Cost Hamiltonian (phase separating)\n",
    "            for basis_state in range(state.n_states):\n",
    "                cost = self.cost_hamiltonian(basis_state)\n",
    "                phase = gamma * cost\n",
    "                state.amplitudes[basis_state] *= np.exp(-1j * phase)\n",
    "            \n",
    "            # Mixer Hamiltonian\n",
    "            state.apply_mixer(2 * beta)\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def expectation_value(self, gammas: List[float], betas: List[float], \n",
    "                         n_qubits: int) -> float:\n",
    "        \"\"\"Calculate expectation value\"\"\"\n",
    "        state = self.run_circuit(gammas, betas, n_qubits)\n",
    "        probabilities = state.get_probabilities()\n",
    "        \n",
    "        expectation = 0\n",
    "        for basis_state in range(state.n_states):\n",
    "            cost = self.cost_hamiltonian(basis_state)\n",
    "            expectation += probabilities[basis_state] * cost\n",
    "        \n",
    "        return expectation\n",
    "\n",
    "print(\"Basic QAOA implementation ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "197fb225",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecursiveQAOA:\n",
    "    \"\"\"Recursive QAOA implementation\"\"\"\n",
    "    \n",
    "    def __init__(self, \n",
    "                 original_problem: Dict,\n",
    "                 confidence_threshold: float = 0.7,\n",
    "                 max_recursion_depth: int = 5,\n",
    "                 min_problem_size: int = 6):\n",
    "        \n",
    "        self.original_problem = original_problem\n",
    "        self.confidence_threshold = confidence_threshold\n",
    "        self.max_recursion_depth = max_recursion_depth\n",
    "        self.min_problem_size = min_problem_size\n",
    "        \n",
    "        # Tracking\n",
    "        self.recursion_history = []\n",
    "        self.fixed_variables = {}\n",
    "    \n",
    "    def create_maxcut_cost_function(self, edges: List[Tuple[int, int]], \n",
    "                                   weights: List[float], n_qubits: int):\n",
    "        \"\"\"Create MaxCut cost function for current problem size\"\"\"\n",
    "        def cost_function(bitstring_int: int) -> float:\n",
    "            # Convert integer to binary array\n",
    "            bitstring = [(bitstring_int >> i) & 1 for i in range(n_qubits)]\n",
    "            \n",
    "            cost = 0\n",
    "            for (i, j), weight in zip(edges, weights):\n",
    "                if i < n_qubits and j < n_qubits:  # Valid for current problem size\n",
    "                    if bitstring[i] != bitstring[j]:\n",
    "                        cost += weight\n",
    "            \n",
    "            return -cost  # Minimize negative (maximize cut)\n",
    "        \n",
    "        return cost_function\n",
    "    \n",
    "    def identify_confident_variables(self, state: QuantumState, \n",
    "                                   threshold: float) -> Dict[int, int]:\n",
    "        \"\"\"Identify variables with high confidence\"\"\"\n",
    "        probabilities = state.get_probabilities()\n",
    "        n_qubits = state.n_qubits\n",
    "        \n",
    "        # Calculate marginal probabilities for each qubit\n",
    "        marginals = np.zeros((n_qubits, 2))  # [qubit][0 or 1]\n",
    "        \n",
    "        for basis_state in range(state.n_states):\n",
    "            prob = probabilities[basis_state]\n",
    "            for qubit in range(n_qubits):\n",
    "                bit_value = (basis_state >> qubit) & 1\n",
    "                marginals[qubit, bit_value] += prob\n",
    "        \n",
    "        # Find confident variables\n",
    "        confident_vars = {}\n",
    "        for qubit in range(n_qubits):\n",
    "            max_prob = max(marginals[qubit])\n",
    "            if max_prob >= threshold:\n",
    "                confident_value = np.argmax(marginals[qubit])\n",
    "                confident_vars[qubit] = confident_value\n",
    "        \n",
    "        return confident_vars\n",
    "    \n",
    "    def reduce_problem(self, edges: List[Tuple[int, int]], \n",
    "                      weights: List[float], \n",
    "                      fixed_vars: Dict[int, int]) -> Tuple[List[Tuple[int, int]], List[float], Dict[int, int]]:\n",
    "        \"\"\"Reduce problem by fixing variables\"\"\"\n",
    "        # Create mapping from old to new variable indices\n",
    "        remaining_vars = [i for i in range(max(max(edges, key=lambda x: max(x))) + 1) \n",
    "                         if i not in fixed_vars]\n",
    "        var_mapping = {old_var: new_var for new_var, old_var in enumerate(remaining_vars)}\n",
    "        \n",
    "        # Filter and remap edges\n",
    "        new_edges = []\n",
    "        new_weights = []\n",
    "        \n",
    "        for (i, j), weight in zip(edges, weights):\n",
    "            # Skip edges involving fixed variables\n",
    "            if i in fixed_vars or j in fixed_vars:\n",
    "                continue\n",
    "            \n",
    "            # Remap to new variable indices\n",
    "            new_i = var_mapping[i]\n",
    "            new_j = var_mapping[j]\n",
    "            new_edges.append((new_i, new_j))\n",
    "            new_weights.append(weight)\n",
    "        \n",
    "        return new_edges, new_weights, var_mapping\n",
    "    \n",
    "    def solve_recursive(self, \n",
    "                       edges: List[Tuple[int, int]], \n",
    "                       weights: List[float], \n",
    "                       depth: int = 0) -> Tuple[Dict[int, int], float]:\n",
    "        \"\"\"Recursively solve the problem\"\"\"\n",
    "        \n",
    "        if depth > self.max_recursion_depth:\n",
    "            print(f\"Max recursion depth {self.max_recursion_depth} reached\")\n",
    "            return {}, 0\n",
    "        \n",
    "        # Determine current problem size\n",
    "        if not edges:\n",
    "            return {}, 0\n",
    "        \n",
    "        n_qubits = max(max(edges, key=lambda x: max(x))) + 1\n",
    "        \n",
    "        print(f\"\\nDepth {depth}: Solving problem with {n_qubits} variables, {len(edges)} edges\")\n",
    "        \n",
    "        # Base case: problem small enough for classical solver or brute force\n",
    "        if n_qubits <= self.min_problem_size:\n",
    "            print(f\"Base case reached: solving {n_qubits}-variable problem classically\")\n",
    "            return self.solve_classically(edges, weights, n_qubits)\n",
    "        \n",
    "        # Run QAOA on current problem\n",
    "        cost_function = self.create_maxcut_cost_function(edges, weights, n_qubits)\n",
    "        qaoa = BasicQAOA(cost_function)\n",
    "        \n",
    "        # Optimize QAOA parameters (simplified)\n",
    "        best_expectation = float('inf')\n",
    "        best_state = None\n",
    "        \n",
    "        # Try different parameter combinations\n",
    "        for p in [1, 2]:  # Circuit depth\n",
    "            for trial in range(3):  # Multiple random starts\n",
    "                gammas = np.random.uniform(0, np.pi, p)\n",
    "                betas = np.random.uniform(0, np.pi/2, p)\n",
    "                \n",
    "                # Simple parameter optimization\n",
    "                def objective(params):\n",
    "                    g = params[:p]\n",
    "                    b = params[p:]\n",
    "                    return qaoa.expectation_value(g, b, n_qubits)\n",
    "                \n",
    "                result = minimize(objective, np.concatenate([gammas, betas]), \n",
    "                                method='COBYLA', \n",
    "                                options={'maxiter': 50, 'disp': False})\n",
    "                \n",
    "                if result.fun < best_expectation:\n",
    "                    best_expectation = result.fun\n",
    "                    opt_gammas = result.x[:p]\n",
    "                    opt_betas = result.x[p:]\n",
    "                    best_state = qaoa.run_circuit(opt_gammas, opt_betas, n_qubits)\n",
    "        \n",
    "        print(f\"QAOA expectation value: {best_expectation:.3f}\")\n",
    "        \n",
    "        # Identify confident variables\n",
    "        confident_vars = self.identify_confident_variables(best_state, self.confidence_threshold)\n",
    "        \n",
    "        print(f\"Found {len(confident_vars)} confident variables: {confident_vars}\")\n",
    "        \n",
    "        if not confident_vars:\n",
    "            print(\"No confident variables found, stopping recursion\")\n",
    "            # Return best solution from sampling\n",
    "            samples = best_state.sample(1000)\n",
    "            best_sample = min(samples, key=cost_function)\n",
    "            solution = {i: (best_sample >> i) & 1 for i in range(n_qubits)}\n",
    "            return solution, cost_function(best_sample)\n",
    "        \n",
    "        # Store this level's results\n",
    "        self.recursion_history.append({\n",
    "            'depth': depth,\n",
    "            'n_qubits': n_qubits,\n",
    "            'n_edges': len(edges),\n",
    "            'confident_vars': confident_vars.copy(),\n",
    "            'expectation': best_expectation\n",
    "        })\n",
    "        \n",
    "        # Update global fixed variables\n",
    "        for var, value in confident_vars.items():\n",
    "            self.fixed_variables[var] = value\n",
    "        \n",
    "        # Reduce problem\n",
    "        reduced_edges, reduced_weights, var_mapping = self.reduce_problem(\n",
    "            edges, weights, confident_vars)\n",
    "        \n",
    "        if not reduced_edges:\n",
    "            print(\"Problem fully reduced!\")\n",
    "            return confident_vars, best_expectation\n",
    "        \n",
    "        # Recursively solve reduced problem\n",
    "        reduced_solution, reduced_cost = self.solve_recursive(\n",
    "            reduced_edges, reduced_weights, depth + 1)\n",
    "        \n",
    "        # Combine solutions\n",
    "        full_solution = confident_vars.copy()\n",
    "        \n",
    "        # Map reduced solution back to original variables\n",
    "        reverse_mapping = {new: old for old, new in var_mapping.items()}\n",
    "        for new_var, value in reduced_solution.items():\n",
    "            if new_var in reverse_mapping:\n",
    "                original_var = reverse_mapping[new_var]\n",
    "                full_solution[original_var] = value\n",
    "        \n",
    "        return full_solution, reduced_cost\n",
    "    \n",
    "    def solve_classically(self, edges: List[Tuple[int, int]], \n",
    "                         weights: List[float], n_qubits: int) -> Tuple[Dict[int, int], float]:\n",
    "        \"\"\"Solve small problems classically\"\"\"\n",
    "        cost_function = self.create_maxcut_cost_function(edges, weights, n_qubits)\n",
    "        \n",
    "        best_cost = float('inf')\n",
    "        best_solution = {}\n",
    "        \n",
    "        # Brute force for small problems\n",
    "        for bitstring_int in range(2**n_qubits):\n",
    "            cost = cost_function(bitstring_int)\n",
    "            if cost < best_cost:\n",
    "                best_cost = cost\n",
    "                best_solution = {i: (bitstring_int >> i) & 1 for i in range(n_qubits)}\n",
    "        \n",
    "        return best_solution, best_cost\n",
    "\n",
    "print(\"Recursive QAOA implementation ready!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a6659eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's test RQAOA on a sample problem\n",
    "def create_test_maxcut_problem(n_nodes: int = 8, edge_prob: float = 0.6) -> Tuple[List[Tuple[int, int]], List[float]]:\n",
    "    \"\"\"Create a random MaxCut problem for testing\"\"\"\n",
    "    edges = []\n",
    "    weights = []\n",
    "    \n",
    "    for i in range(n_nodes):\n",
    "        for j in range(i + 1, n_nodes):\n",
    "            if np.random.random() < edge_prob:\n",
    "                edges.append((i, j))\n",
    "                weights.append(np.random.uniform(0.5, 2.0))\n",
    "    \n",
    "    return edges, weights\n",
    "\n",
    "# Create test problem\n",
    "test_edges, test_weights = create_test_maxcut_problem(8, 0.4)\n",
    "print(f\"Test problem: {len(test_edges)} edges on 8 nodes\")\n",
    "print(f\"Edges: {test_edges[:5]}...\")\n",
    "\n",
    "# Test RQAOA\n",
    "rqaoa = RecursiveQAOA(\n",
    "    original_problem={'edges': test_edges, 'weights': test_weights},\n",
    "    confidence_threshold=0.65,\n",
    "    max_recursion_depth=3,\n",
    "    min_problem_size=4\n",
    ")\n",
    "\n",
    "print(\"\\n=== Running Recursive QAOA ===\")\n",
    "start_time = time.time()\n",
    "solution, cost = rqaoa.solve_recursive(test_edges, test_weights)\n",
    "rqaoa_time = time.time() - start_time\n",
    "\n",
    "print(f\"\\nRQAOA Solution: {solution}\")\n",
    "print(f\"Cost: {cost:.3f}\")\n",
    "print(f\"Time: {rqaoa_time:.2f}s\")\n",
    "print(f\"Recursion levels: {len(rqaoa.recursion_history)}\")\n",
    "\n",
    "# Show recursion progression\n",
    "for level in rqaoa.recursion_history:\n",
    "    print(f\"Level {level['depth']}: {level['n_qubits']} vars → {len(level['confident_vars'])} fixed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db05804a",
   "metadata": {},
   "source": [
    "## 2. Multi-Angle QAOA (MA-QAOA)\n",
    "\n",
    "Multi-Angle QAOA allows different angles for different qubits/edges:\n",
    "- **Standard QAOA**: Same γ and β for all gates\n",
    "- **MA-QAOA**: Individual angles for each constraint/mixer\n",
    "\n",
    "**Advantages**:\n",
    "- More flexible parameter space\n",
    "- Can capture problem structure better\n",
    "- Often achieves higher approximation ratios\n",
    "\n",
    "**Challenges**:\n",
    "- Exponentially more parameters to optimize\n",
    "- Risk of overfitting with limited quantum resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71e019bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiAngleQAOA:\n",
    "    \"\"\"Multi-Angle QAOA with individual parameters per constraint\"\"\"\n",
    "    \n",
    "    def __init__(self, edges: List[Tuple[int, int]], weights: List[float]):\n",
    "        self.edges = edges\n",
    "        self.weights = weights\n",
    "        self.n_qubits = max(max(edges, key=lambda x: max(x))) + 1 if edges else 0\n",
    "        self.n_edges = len(edges)\n",
    "    \n",
    "    def create_cost_function(self):\n",
    "        \"\"\"Create MaxCut cost function\"\"\"\n",
    "        def cost_function(bitstring_int: int) -> float:\n",
    "            bitstring = [(bitstring_int >> i) & 1 for i in range(self.n_qubits)]\n",
    "            cost = 0\n",
    "            for (i, j), weight in zip(self.edges, self.weights):\n",
    "                if bitstring[i] != bitstring[j]:\n",
    "                    cost += weight\n",
    "            return -cost  # Minimize negative (maximize cut)\n",
    "        return cost_function\n",
    "    \n",
    "    def run_circuit(self, gammas_per_edge: List[float], \n",
    "                   betas_per_qubit: List[float], layers: int = 1) -> QuantumState:\n",
    "        \"\"\"Run MA-QAOA circuit with individual angles\"\"\"\n",
    "        state = QuantumState(self.n_qubits)\n",
    "        \n",
    "        # Reshape parameters for multiple layers\n",
    "        gammas_per_layer = np.array(gammas_per_edge).reshape(layers, self.n_edges)\n",
    "        betas_per_layer = np.array(betas_per_qubit).reshape(layers, self.n_qubits)\n",
    "        \n",
    "        for layer in range(layers):\n",
    "            # Cost Hamiltonian with individual edge angles\n",
    "            for basis_state in range(state.n_states):\n",
    "                bitstring = [(basis_state >> i) & 1 for i in range(self.n_qubits)]\n",
    "                total_phase = 0\n",
    "                \n",
    "                for edge_idx, ((i, j), weight) in enumerate(zip(self.edges, self.weights)):\n",
    "                    if bitstring[i] != bitstring[j]:  # Edge is cut\n",
    "                        total_phase += gammas_per_layer[layer, edge_idx] * weight\n",
    "                \n",
    "                state.amplitudes[basis_state] *= np.exp(-1j * total_phase)\n",
    "            \n",
    "            # Mixer Hamiltonian with individual qubit angles\n",
    "            for qubit in range(self.n_qubits):\n",
    "                beta = betas_per_layer[layer, qubit]\n",
    "                # Apply individual X rotation to this qubit\n",
    "                new_amplitudes = state.amplitudes.copy()\n",
    "                cos_half = np.cos(beta)\n",
    "                sin_half = -1j * np.sin(beta)\n",
    "                \n",
    "                for basis_state in range(state.n_states):\n",
    "                    flipped_state = basis_state ^ (1 << qubit)\n",
    "                    new_amplitudes[basis_state] = (\n",
    "                        cos_half * state.amplitudes[basis_state] + \n",
    "                        sin_half * state.amplitudes[flipped_state]\n",
    "                    )\n",
    "                \n",
    "                state.amplitudes = new_amplitudes\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def expectation_value(self, gammas_per_edge: List[float], \n",
    "                         betas_per_qubit: List[float], layers: int = 1) -> float:\n",
    "        \"\"\"Calculate expectation value for MA-QAOA\"\"\"\n",
    "        state = self.run_circuit(gammas_per_edge, betas_per_qubit, layers)\n",
    "        probabilities = state.get_probabilities()\n",
    "        cost_function = self.create_cost_function()\n",
    "        \n",
    "        expectation = 0\n",
    "        for basis_state in range(state.n_states):\n",
    "            cost = cost_function(basis_state)\n",
    "            expectation += probabilities[basis_state] * cost\n",
    "        \n",
    "        return expectation\n",
    "    \n",
    "    def optimize_parameters(self, layers: int = 1, max_iterations: int = 100) -> Dict:\n",
    "        \"\"\"Optimize MA-QAOA parameters\"\"\"\n",
    "        # Initialize parameters\n",
    "        n_gamma_params = self.n_edges * layers\n",
    "        n_beta_params = self.n_qubits * layers\n",
    "        \n",
    "        # Random initialization\n",
    "        initial_gammas = np.random.uniform(0, np.pi, n_gamma_params)\n",
    "        initial_betas = np.random.uniform(0, np.pi/2, n_beta_params)\n",
    "        initial_params = np.concatenate([initial_gammas, initial_betas])\n",
    "        \n",
    "        def objective(params):\n",
    "            gammas = params[:n_gamma_params]\n",
    "            betas = params[n_gamma_params:]\n",
    "            return self.expectation_value(gammas, betas, layers)\n",
    "        \n",
    "        # Optimize\n",
    "        result = minimize(objective, initial_params, \n",
    "                         method='COBYLA',\n",
    "                         options={'maxiter': max_iterations, 'disp': False})\n",
    "        \n",
    "        optimal_gammas = result.x[:n_gamma_params]\n",
    "        optimal_betas = result.x[n_gamma_params:]\n",
    "        \n",
    "        return {\n",
    "            'optimal_gammas': optimal_gammas,\n",
    "            'optimal_betas': optimal_betas,\n",
    "            'optimal_value': result.fun,\n",
    "            'success': result.success,\n",
    "            'n_evaluations': result.nfev\n",
    "        }\n",
    "\n",
    "print(\"Multi-Angle QAOA implementation ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e26ce2",
   "metadata": {},
   "source": [
    "## 3. Warm-Starting QAOA\n",
    "\n",
    "Warm-starting initializes QAOA with classical solutions:\n",
    "\n",
    "1. **Find classical solution** (greedy, simulated annealing, etc.)\n",
    "2. **Initialize quantum state** to encode this solution\n",
    "3. **Run short QAOA** to refine the solution\n",
    "\n",
    "**Benefits**:\n",
    "- Faster convergence\n",
    "- Better final solutions\n",
    "- Reduced parameter landscape complexity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e8a1289",
   "metadata": {},
   "outputs": [],
   "source": [
    "class WarmStartQAOA:\n",
    "    \"\"\"QAOA with warm-starting from classical solutions\"\"\"\n",
    "    \n",
    "    def __init__(self, edges: List[Tuple[int, int]], weights: List[float]):\n",
    "        self.edges = edges\n",
    "        self.weights = weights\n",
    "        self.n_qubits = max(max(edges, key=lambda x: max(x))) + 1 if edges else 0\n",
    "    \n",
    "    def greedy_maxcut(self) -> List[int]:\n",
    "        \"\"\"Simple greedy algorithm for initial solution\"\"\"\n",
    "        assignment = [-1] * self.n_qubits  # -1 means unassigned\n",
    "        \n",
    "        # Start with node 0 in partition 0\n",
    "        assignment[0] = 0\n",
    "        \n",
    "        for node in range(1, self.n_qubits):\n",
    "            # Calculate benefit of assigning to each partition\n",
    "            benefit_0 = 0  # Benefit of assigning to partition 0\n",
    "            benefit_1 = 0  # Benefit of assigning to partition 1\n",
    "            \n",
    "            for (i, j), weight in zip(self.edges, self.weights):\n",
    "                if i == node and assignment[j] != -1:\n",
    "                    if assignment[j] == 0:\n",
    "                        benefit_1 += weight  # Different partitions\n",
    "                    else:\n",
    "                        benefit_0 += weight\n",
    "                elif j == node and assignment[i] != -1:\n",
    "                    if assignment[i] == 0:\n",
    "                        benefit_1 += weight\n",
    "                    else:\n",
    "                        benefit_0 += weight\n",
    "            \n",
    "            # Assign to partition with higher benefit\n",
    "            assignment[node] = 0 if benefit_0 >= benefit_1 else 1\n",
    "        \n",
    "        return assignment\n",
    "    \n",
    "    def create_warm_start_state(self, classical_solution: List[int], \n",
    "                               bias_strength: float = 2.0) -> QuantumState:\n",
    "        \"\"\"Create quantum state biased toward classical solution\"\"\"\n",
    "        state = QuantumState(self.n_qubits)\n",
    "        \n",
    "        # Start with uniform superposition\n",
    "        state.amplitudes = np.ones(state.n_states, dtype=complex) / np.sqrt(state.n_states)\n",
    "        \n",
    "        # Apply bias toward classical solution\n",
    "        classical_bitstring = sum(bit * (2**i) for i, bit in enumerate(classical_solution))\n",
    "        \n",
    "        for basis_state in range(state.n_states):\n",
    "            # Calculate Hamming distance from classical solution\n",
    "            hamming_distance = bin(basis_state ^ classical_bitstring).count('1')\n",
    "            \n",
    "            # Apply exponential bias (closer states get higher amplitude)\n",
    "            bias_factor = np.exp(-bias_strength * hamming_distance / self.n_qubits)\n",
    "            state.amplitudes[basis_state] *= bias_factor\n",
    "        \n",
    "        # Renormalize\n",
    "        norm = np.sqrt(np.sum(np.abs(state.amplitudes)**2))\n",
    "        state.amplitudes /= norm\n",
    "        \n",
    "        return state\n",
    "    \n",
    "    def run_warm_qaoa(self, warm_start_solution: List[int], \n",
    "                     layers: int = 1, bias_strength: float = 2.0) -> Dict:\n",
    "        \"\"\"Run QAOA with warm starting\"\"\"\n",
    "        # Create cost function\n",
    "        def cost_function(bitstring_int: int) -> float:\n",
    "            bitstring = [(bitstring_int >> i) & 1 for i in range(self.n_qubits)]\n",
    "            cost = 0\n",
    "            for (i, j), weight in zip(self.edges, self.weights):\n",
    "                if bitstring[i] != bitstring[j]:\n",
    "                    cost += weight\n",
    "            return -cost\n",
    "        \n",
    "        # Initialize with warm start\n",
    "        initial_state = self.create_warm_start_state(warm_start_solution, bias_strength)\n",
    "        \n",
    "        # Optimize QAOA parameters\n",
    "        def objective(params):\n",
    "            gammas = params[:layers]\n",
    "            betas = params[layers:]\n",
    "            \n",
    "            # Start from warm state instead of uniform superposition\n",
    "            state = QuantumState(self.n_qubits)\n",
    "            state.amplitudes = initial_state.amplitudes.copy()\n",
    "            \n",
    "            # Apply QAOA layers\n",
    "            for gamma, beta in zip(gammas, betas):\n",
    "                # Cost Hamiltonian\n",
    "                for basis_state in range(state.n_states):\n",
    "                    cost = cost_function(basis_state)\n",
    "                    phase = gamma * cost\n",
    "                    state.amplitudes[basis_state] *= np.exp(-1j * phase)\n",
    "                \n",
    "                # Mixer Hamiltonian\n",
    "                state.apply_mixer(2 * beta)\n",
    "            \n",
    "            # Calculate expectation value\n",
    "            probabilities = state.get_probabilities()\n",
    "            expectation = sum(prob * cost_function(i) \n",
    "                            for i, prob in enumerate(probabilities))\n",
    "            return expectation\n",
    "        \n",
    "        # Optimize\n",
    "        initial_params = np.random.uniform(0, np.pi/2, 2*layers)\n",
    "        result = minimize(objective, initial_params, method='COBYLA',\n",
    "                         options={'maxiter': 100, 'disp': False})\n",
    "        \n",
    "        return {\n",
    "            'classical_solution': warm_start_solution,\n",
    "            'classical_cost': -cost_function(sum(bit * (2**i) for i, bit in enumerate(warm_start_solution))),\n",
    "            'optimal_params': result.x,\n",
    "            'qaoa_cost': -result.fun,\n",
    "            'improvement': -result.fun - (-cost_function(sum(bit * (2**i) for i, bit in enumerate(warm_start_solution)))),\n",
    "            'success': result.success\n",
    "        }\n",
    "\n",
    "print(\"Warm-starting QAOA implementation ready!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f138735",
   "metadata": {},
   "source": [
    "## 4. Comprehensive Benchmarking\n",
    "\n",
    "Let's compare all QAOA variants on the same problems:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39eecfd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark_qaoa_methods(edges: List[Tuple[int, int]], \n",
    "                          weights: List[float],\n",
    "                          problem_name: str = \"Test\") -> Dict:\n",
    "    \"\"\"Comprehensive benchmark of all QAOA methods\"\"\"\n",
    "    \n",
    "    n_qubits = max(max(edges, key=lambda x: max(x))) + 1 if edges else 0\n",
    "    results = {'problem': problem_name, 'n_qubits': n_qubits, 'n_edges': len(edges)}\n",
    "    \n",
    "    # Classical optimal (brute force for small problems)\n",
    "    if n_qubits <= 12:\n",
    "        print(f\"Finding classical optimum for {n_qubits}-qubit problem...\")\n",
    "        def cost_function(bitstring_int: int) -> float:\n",
    "            bitstring = [(bitstring_int >> i) & 1 for i in range(n_qubits)]\n",
    "            cost = 0\n",
    "            for (i, j), weight in zip(edges, weights):\n",
    "                if bitstring[i] != bitstring[j]:\n",
    "                    cost += weight\n",
    "            return cost\n",
    "        \n",
    "        best_cost = 0\n",
    "        best_solution = 0\n",
    "        for bitstring_int in range(2**n_qubits):\n",
    "            cost = cost_function(bitstring_int)\n",
    "            if cost > best_cost:\n",
    "                best_cost = cost\n",
    "                best_solution = bitstring_int\n",
    "        \n",
    "        results['classical_optimal'] = {\n",
    "            'cost': best_cost,\n",
    "            'solution': [(best_solution >> i) & 1 for i in range(n_qubits)]\n",
    "        }\n",
    "        print(f\"Classical optimum: {best_cost:.3f}\")\n",
    "    else:\n",
    "        results['classical_optimal'] = None\n",
    "        print(\"Problem too large for classical brute force\")\n",
    "    \n",
    "    # 1. Standard QAOA\n",
    "    print(\"\\n=== Standard QAOA ===\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    def standard_cost_function(bitstring_int: int) -> float:\n",
    "        bitstring = [(bitstring_int >> i) & 1 for i in range(n_qubits)]\n",
    "        cost = 0\n",
    "        for (i, j), weight in zip(edges, weights):\n",
    "            if bitstring[i] != bitstring[j]:\n",
    "                cost += weight\n",
    "        return -cost  # Minimize negative\n",
    "    \n",
    "    standard_qaoa = BasicQAOA(standard_cost_function)\n",
    "    \n",
    "    # Simple parameter optimization for standard QAOA\n",
    "    best_expectation = float('inf')\n",
    "    best_solution_standard = None\n",
    "    \n",
    "    for layers in [1, 2]:\n",
    "        for trial in range(3):\n",
    "            initial_params = np.random.uniform(0, np.pi/2, 2*layers)\n",
    "            \n",
    "            def objective(params):\n",
    "                gammas = params[:layers]\n",
    "                betas = params[layers:]\n",
    "                return standard_qaoa.expectation_value(gammas, betas, n_qubits)\n",
    "            \n",
    "            result = minimize(objective, initial_params, method='COBYLA',\n",
    "                             options={'maxiter': 50, 'disp': False})\n",
    "            \n",
    "            if result.fun < best_expectation:\n",
    "                best_expectation = result.fun\n",
    "                opt_gammas = result.x[:layers]\n",
    "                opt_betas = result.x[layers:]\n",
    "                final_state = standard_qaoa.run_circuit(opt_gammas, opt_betas, n_qubits)\n",
    "                samples = final_state.sample(1000)\n",
    "                best_sample = min(samples, key=standard_cost_function)\n",
    "                best_solution_standard = [(best_sample >> i) & 1 for i in range(n_qubits)]\n",
    "    \n",
    "    standard_time = time.time() - start_time\n",
    "    results['standard_qaoa'] = {\n",
    "        'cost': -best_expectation,\n",
    "        'solution': best_solution_standard,\n",
    "        'time': standard_time\n",
    "    }\n",
    "    print(f\"Standard QAOA: {-best_expectation:.3f} (time: {standard_time:.2f}s)\")\n",
    "    \n",
    "    # 2. Multi-Angle QAOA\n",
    "    print(\"\\n=== Multi-Angle QAOA ===\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ma_qaoa = MultiAngleQAOA(edges, weights)\n",
    "    ma_result = ma_qaoa.optimize_parameters(layers=1, max_iterations=50)\n",
    "    \n",
    "    # Get best solution from MA-QAOA\n",
    "    final_state_ma = ma_qaoa.run_circuit(ma_result['optimal_gammas'], \n",
    "                                        ma_result['optimal_betas'], 1)\n",
    "    samples_ma = final_state_ma.sample(1000)\n",
    "    best_sample_ma = min(samples_ma, key=lambda x: ma_qaoa.create_cost_function()(x))\n",
    "    best_solution_ma = [(best_sample_ma >> i) & 1 for i in range(n_qubits)]\n",
    "    \n",
    "    ma_time = time.time() - start_time\n",
    "    results['multi_angle_qaoa'] = {\n",
    "        'cost': -ma_result['optimal_value'],\n",
    "        'solution': best_solution_ma,\n",
    "        'time': ma_time,\n",
    "        'n_parameters': len(ma_result['optimal_gammas']) + len(ma_result['optimal_betas'])\n",
    "    }\n",
    "    print(f\"MA-QAOA: {-ma_result['optimal_value']:.3f} (time: {ma_time:.2f}s, params: {results['multi_angle_qaoa']['n_parameters']})\")\n",
    "    \n",
    "    # 3. Warm-Start QAOA\n",
    "    print(\"\\n=== Warm-Start QAOA ===\")\n",
    "    start_time = time.time()\n",
    "    \n",
    "    ws_qaoa = WarmStartQAOA(edges, weights)\n",
    "    classical_init = ws_qaoa.greedy_maxcut()\n",
    "    ws_result = ws_qaoa.run_warm_qaoa(classical_init, layers=1)\n",
    "    \n",
    "    ws_time = time.time() - start_time\n",
    "    results['warm_start_qaoa'] = {\n",
    "        'classical_cost': ws_result['classical_cost'],\n",
    "        'qaoa_cost': ws_result['qaoa_cost'],\n",
    "        'improvement': ws_result['improvement'],\n",
    "        'time': ws_time\n",
    "    }\n",
    "    print(f\"Warm-Start: {ws_result['classical_cost']:.3f} → {ws_result['qaoa_cost']:.3f} \"\n",
    "          f\"(+{ws_result['improvement']:.3f}, time: {ws_time:.2f}s)\")\n",
    "    \n",
    "    # 4. Recursive QAOA (if problem is large enough)\n",
    "    if n_qubits >= 6:\n",
    "        print(\"\\n=== Recursive QAOA ===\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        rqaoa = RecursiveQAOA(\n",
    "            original_problem={'edges': edges, 'weights': weights},\n",
    "            confidence_threshold=0.6,\n",
    "            max_recursion_depth=2,\n",
    "            min_problem_size=4\n",
    "        )\n",
    "        \n",
    "        rqaoa_solution, rqaoa_cost = rqaoa.solve_recursive(edges, weights)\n",
    "        rqaoa_time = time.time() - start_time\n",
    "        \n",
    "        # Calculate actual cost of RQAOA solution\n",
    "        actual_cost = 0\n",
    "        for (i, j), weight in zip(edges, weights):\n",
    "            if i in rqaoa_solution and j in rqaoa_solution:\n",
    "                if rqaoa_solution[i] != rqaoa_solution[j]:\n",
    "                    actual_cost += weight\n",
    "        \n",
    "        results['recursive_qaoa'] = {\n",
    "            'cost': actual_cost,\n",
    "            'solution': rqaoa_solution,\n",
    "            'time': rqaoa_time,\n",
    "            'recursion_levels': len(rqaoa.recursion_history)\n",
    "        }\n",
    "        print(f\"RQAOA: {actual_cost:.3f} (time: {rqaoa_time:.2f}s, levels: {len(rqaoa.recursion_history)})\")\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run comprehensive benchmark\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"COMPREHENSIVE QAOA BENCHMARK\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "# Test on medium-sized problem\n",
    "test_edges, test_weights = create_test_maxcut_problem(8, 0.4)\n",
    "benchmark_results = benchmark_qaoa_methods(test_edges, test_weights, \"8-node Random\")\n",
    "\n",
    "# Print summary\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"BENCHMARK SUMMARY\")\n",
    "print(\"=\"*40)\n",
    "\n",
    "if benchmark_results['classical_optimal']:\n",
    "    optimal_cost = benchmark_results['classical_optimal']['cost']\n",
    "    print(f\"Classical Optimal: {optimal_cost:.3f}\")\n",
    "    print(\"\\nApproximation Ratios:\")\n",
    "    \n",
    "    methods = ['standard_qaoa', 'multi_angle_qaoa', 'warm_start_qaoa', 'recursive_qaoa']\n",
    "    method_names = ['Standard QAOA', 'Multi-Angle QAOA', 'Warm-Start QAOA', 'Recursive QAOA']\n",
    "    \n",
    "    for method, name in zip(methods, method_names):\n",
    "        if method in benchmark_results:\n",
    "            if method == 'warm_start_qaoa':\n",
    "                cost = benchmark_results[method]['qaoa_cost']\n",
    "            else:\n",
    "                cost = benchmark_results[method]['cost']\n",
    "            ratio = cost / optimal_cost if optimal_cost > 0 else 0\n",
    "            time_taken = benchmark_results[method]['time']\n",
    "            print(f\"  {name}: {ratio:.3f} (cost: {cost:.3f}, time: {time_taken:.2f}s)\")\n",
    "\n",
    "print(\"\\nTime Comparison:\")\n",
    "for method, name in zip(methods, method_names):\n",
    "    if method in benchmark_results:\n",
    "        time_taken = benchmark_results[method]['time']\n",
    "        print(f\"  {name}: {time_taken:.2f}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9004344f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize benchmark results\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Plot 1: Cost comparison\n",
    "plt.subplot(2, 3, 1)\n",
    "methods = []\n",
    "costs = []\n",
    "colors = ['blue', 'green', 'orange', 'red', 'purple']\n",
    "\n",
    "if benchmark_results['classical_optimal']:\n",
    "    methods.append('Classical\\nOptimal')\n",
    "    costs.append(benchmark_results['classical_optimal']['cost'])\n",
    "\n",
    "if 'standard_qaoa' in benchmark_results:\n",
    "    methods.append('Standard\\nQAOA')\n",
    "    costs.append(benchmark_results['standard_qaoa']['cost'])\n",
    "\n",
    "if 'multi_angle_qaoa' in benchmark_results:\n",
    "    methods.append('Multi-Angle\\nQAOA')\n",
    "    costs.append(benchmark_results['multi_angle_qaoa']['cost'])\n",
    "\n",
    "if 'warm_start_qaoa' in benchmark_results:\n",
    "    methods.append('Warm-Start\\nQAOA')\n",
    "    costs.append(benchmark_results['warm_start_qaoa']['qaoa_cost'])\n",
    "\n",
    "if 'recursive_qaoa' in benchmark_results:\n",
    "    methods.append('Recursive\\nQAOA')\n",
    "    costs.append(benchmark_results['recursive_qaoa']['cost'])\n",
    "\n",
    "bars = plt.bar(methods, costs, color=colors[:len(methods)])\n",
    "plt.title('Cost Comparison')\n",
    "plt.ylabel('MaxCut Value')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels on bars\n",
    "for bar, cost in zip(bars, costs):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "             f'{cost:.2f}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 2: Time comparison\n",
    "plt.subplot(2, 3, 2)\n",
    "time_methods = []\n",
    "times = []\n",
    "\n",
    "if 'standard_qaoa' in benchmark_results:\n",
    "    time_methods.append('Standard\\nQAOA')\n",
    "    times.append(benchmark_results['standard_qaoa']['time'])\n",
    "\n",
    "if 'multi_angle_qaoa' in benchmark_results:\n",
    "    time_methods.append('Multi-Angle\\nQAOA')\n",
    "    times.append(benchmark_results['multi_angle_qaoa']['time'])\n",
    "\n",
    "if 'warm_start_qaoa' in benchmark_results:\n",
    "    time_methods.append('Warm-Start\\nQAOA')\n",
    "    times.append(benchmark_results['warm_start_qaoa']['time'])\n",
    "\n",
    "if 'recursive_qaoa' in benchmark_results:\n",
    "    time_methods.append('Recursive\\nQAOA')\n",
    "    times.append(benchmark_results['recursive_qaoa']['time'])\n",
    "\n",
    "bars = plt.bar(time_methods, times, color=colors[1:len(time_methods)+1])\n",
    "plt.title('Execution Time Comparison')\n",
    "plt.ylabel('Time (seconds)')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Add value labels\n",
    "for bar, time_val in zip(bars, times):\n",
    "    plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.001,\n",
    "             f'{time_val:.2f}s', ha='center', va='bottom')\n",
    "\n",
    "# Plot 3: Approximation ratios (if optimal is known)\n",
    "if benchmark_results['classical_optimal']:\n",
    "    plt.subplot(2, 3, 3)\n",
    "    optimal_cost = benchmark_results['classical_optimal']['cost']\n",
    "    \n",
    "    qaoa_methods = []\n",
    "    ratios = []\n",
    "    \n",
    "    if 'standard_qaoa' in benchmark_results:\n",
    "        qaoa_methods.append('Standard\\nQAOA')\n",
    "        ratios.append(benchmark_results['standard_qaoa']['cost'] / optimal_cost)\n",
    "    \n",
    "    if 'multi_angle_qaoa' in benchmark_results:\n",
    "        qaoa_methods.append('Multi-Angle\\nQAOA')\n",
    "        ratios.append(benchmark_results['multi_angle_qaoa']['cost'] / optimal_cost)\n",
    "    \n",
    "    if 'warm_start_qaoa' in benchmark_results:\n",
    "        qaoa_methods.append('Warm-Start\\nQAOA')\n",
    "        ratios.append(benchmark_results['warm_start_qaoa']['qaoa_cost'] / optimal_cost)\n",
    "    \n",
    "    if 'recursive_qaoa' in benchmark_results:\n",
    "        qaoa_methods.append('Recursive\\nQAOA')\n",
    "        ratios.append(benchmark_results['recursive_qaoa']['cost'] / optimal_cost)\n",
    "    \n",
    "    bars = plt.bar(qaoa_methods, ratios, color=colors[1:len(qaoa_methods)+1])\n",
    "    plt.title('Approximation Ratios')\n",
    "    plt.ylabel('Ratio to Optimal')\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.axhline(y=1.0, color='black', linestyle='--', alpha=0.5, label='Optimal')\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar, ratio in zip(bars, ratios):\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,\n",
    "                 f'{ratio:.3f}', ha='center', va='bottom')\n",
    "\n",
    "# Plot 4: Parameter scaling\n",
    "plt.subplot(2, 3, 4)\n",
    "if 'multi_angle_qaoa' in benchmark_results:\n",
    "    n_params_standard = 2  # gamma and beta for 1 layer\n",
    "    n_params_ma = benchmark_results['multi_angle_qaoa']['n_parameters']\n",
    "    \n",
    "    plt.bar(['Standard QAOA', 'Multi-Angle QAOA'], \n",
    "            [n_params_standard, n_params_ma], \n",
    "            color=['blue', 'green'])\n",
    "    plt.title('Number of Parameters')\n",
    "    plt.ylabel('Parameter Count')\n",
    "    \n",
    "    for i, val in enumerate([n_params_standard, n_params_ma]):\n",
    "        plt.text(i, val + 0.5, str(val), ha='center', va='bottom')\n",
    "\n",
    "# Plot 5: Warm-start improvement\n",
    "if 'warm_start_qaoa' in benchmark_results:\n",
    "    plt.subplot(2, 3, 5)\n",
    "    classical_cost = benchmark_results['warm_start_qaoa']['classical_cost']\n",
    "    qaoa_cost = benchmark_results['warm_start_qaoa']['qaoa_cost']\n",
    "    \n",
    "    plt.bar(['Classical\\nInitialization', 'After QAOA\\nRefinement'], \n",
    "            [classical_cost, qaoa_cost], \n",
    "            color=['orange', 'red'])\n",
    "    plt.title('Warm-Start Improvement')\n",
    "    plt.ylabel('MaxCut Value')\n",
    "    \n",
    "    # Show improvement\n",
    "    improvement = qaoa_cost - classical_cost\n",
    "    plt.annotate(f'+{improvement:.3f}', \n",
    "                xy=(1, qaoa_cost), xytext=(1, qaoa_cost + 0.1),\n",
    "                arrowprops=dict(arrowstyle='->', color='black'),\n",
    "                ha='center', fontweight='bold')\n",
    "\n",
    "# Plot 6: Problem structure visualization\n",
    "plt.subplot(2, 3, 6)\n",
    "# Create a simple graph visualization\n",
    "G = nx.Graph()\n",
    "for (i, j), weight in zip(test_edges, test_weights):\n",
    "    G.add_edge(i, j, weight=weight)\n",
    "\n",
    "pos = nx.spring_layout(G, seed=42)\n",
    "nx.draw(G, pos, with_labels=True, node_color='lightblue', \n",
    "        node_size=500, font_size=10, font_weight='bold')\n",
    "\n",
    "# Draw edge weights\n",
    "edge_labels = {(i, j): f'{w:.1f}' for (i, j), w in zip(test_edges, test_weights)}\n",
    "nx.draw_networkx_edge_labels(G, pos, edge_labels, font_size=8)\n",
    "\n",
    "plt.title(f'Problem Graph\\n({len(G.nodes)} nodes, {len(G.edges)} edges)')\n",
    "plt.axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\nVisualization complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36709836",
   "metadata": {},
   "source": [
    "## 🎯 Practical Exercises\n",
    "\n",
    "### Exercise 1: Parameter Sensitivity Analysis\n",
    "Analyze how sensitive each QAOA variant is to parameter initialization.\n",
    "\n",
    "### Exercise 2: Scaling Behavior\n",
    "Study how performance changes with problem size for each method.\n",
    "\n",
    "### Exercise 3: Problem Structure Impact\n",
    "Test on different graph types (complete, sparse, regular) to understand when each method excels.\n",
    "\n",
    "### Exercise 4: Hybrid Optimization\n",
    "Combine multiple methods (e.g., warm-start + recursive QAOA)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a256a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exercise 1: Parameter Sensitivity Analysis\n",
    "def parameter_sensitivity_analysis(edges, weights, n_trials=10):\n",
    "    \"\"\"Analyze parameter sensitivity for different QAOA variants\"\"\"\n",
    "    print(\"=== Parameter Sensitivity Analysis ===\")\n",
    "    \n",
    "    # Test standard QAOA with different initializations\n",
    "    def test_cost_function(bitstring_int: int) -> float:\n",
    "        n_qubits = max(max(edges, key=lambda x: max(x))) + 1\n",
    "        bitstring = [(bitstring_int >> i) & 1 for i in range(n_qubits)]\n",
    "        cost = 0\n",
    "        for (i, j), weight in zip(edges, weights):\n",
    "            if bitstring[i] != bitstring[j]:\n",
    "                cost += weight\n",
    "        return -cost\n",
    "    \n",
    "    qaoa = BasicQAOA(test_cost_function)\n",
    "    n_qubits = max(max(edges, key=lambda x: max(x))) + 1\n",
    "    \n",
    "    standard_results = []\n",
    "    for trial in range(n_trials):\n",
    "        # Random initialization\n",
    "        gamma = np.random.uniform(0, np.pi)\n",
    "        beta = np.random.uniform(0, np.pi/2)\n",
    "        \n",
    "        def objective(params):\n",
    "            return qaoa.expectation_value([params[0]], [params[1]], n_qubits)\n",
    "        \n",
    "        result = minimize(objective, [gamma, beta], method='COBYLA',\n",
    "                         options={'maxiter': 30, 'disp': False})\n",
    "        standard_results.append(-result.fun)\n",
    "    \n",
    "    print(f\"Standard QAOA (n={n_trials} trials):\")\n",
    "    print(f\"  Mean: {np.mean(standard_results):.3f} ± {np.std(standard_results):.3f}\")\n",
    "    print(f\"  Range: [{np.min(standard_results):.3f}, {np.max(standard_results):.3f}]\")\n",
    "    \n",
    "    # Test Multi-Angle QAOA sensitivity\n",
    "    ma_qaoa = MultiAngleQAOA(edges, weights)\n",
    "    ma_results = []\n",
    "    \n",
    "    for trial in range(n_trials):\n",
    "        result = ma_qaoa.optimize_parameters(layers=1, max_iterations=30)\n",
    "        ma_results.append(-result['optimal_value'])\n",
    "    \n",
    "    print(f\"\\nMulti-Angle QAOA (n={n_trials} trials):\")\n",
    "    print(f\"  Mean: {np.mean(ma_results):.3f} ± {np.std(ma_results):.3f}\")\n",
    "    print(f\"  Range: [{np.min(ma_results):.3f}, {np.max(ma_results):.3f}]\")\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.hist(standard_results, bins=5, alpha=0.7, label='Standard QAOA')\n",
    "    plt.xlabel('MaxCut Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Standard QAOA Parameter Sensitivity')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.hist(ma_results, bins=5, alpha=0.7, label='Multi-Angle QAOA', color='green')\n",
    "    plt.xlabel('MaxCut Value')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.title('Multi-Angle QAOA Parameter Sensitivity')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return {\n",
    "        'standard': {'mean': np.mean(standard_results), 'std': np.std(standard_results)},\n",
    "        'multi_angle': {'mean': np.mean(ma_results), 'std': np.std(ma_results)}\n",
    "    }\n",
    "\n",
    "# Exercise 2: Scaling Behavior\n",
    "def scaling_analysis(max_nodes=10):\n",
    "    \"\"\"Analyze how methods scale with problem size\"\"\"\n",
    "    print(\"\\n=== Scaling Behavior Analysis ===\")\n",
    "    \n",
    "    node_counts = range(4, max_nodes + 1, 2)\n",
    "    methods_data = {\n",
    "        'standard_qaoa': {'costs': [], 'times': []},\n",
    "        'multi_angle_qaoa': {'costs': [], 'times': []},\n",
    "        'warm_start_qaoa': {'costs': [], 'times': []}\n",
    "    }\n",
    "    \n",
    "    for n_nodes in node_counts:\n",
    "        print(f\"\\nTesting {n_nodes} nodes...\")\n",
    "        edges, weights = create_test_maxcut_problem(n_nodes, 0.5)\n",
    "        \n",
    "        # Standard QAOA\n",
    "        start_time = time.time()\n",
    "        def cost_func(bitstring_int: int) -> float:\n",
    "            bitstring = [(bitstring_int >> i) & 1 for i in range(n_nodes)]\n",
    "            cost = 0\n",
    "            for (i, j), weight in zip(edges, weights):\n",
    "                if bitstring[i] != bitstring[j]:\n",
    "                    cost += weight\n",
    "            return -cost\n",
    "        \n",
    "        qaoa = BasicQAOA(cost_func)\n",
    "        result = minimize(lambda params: qaoa.expectation_value([params[0]], [params[1]], n_nodes),\n",
    "                         [np.pi/4, np.pi/8], method='COBYLA',\n",
    "                         options={'maxiter': 20, 'disp': False})\n",
    "        standard_time = time.time() - start_time\n",
    "        \n",
    "        methods_data['standard_qaoa']['costs'].append(-result.fun)\n",
    "        methods_data['standard_qaoa']['times'].append(standard_time)\n",
    "        \n",
    "        # Multi-Angle QAOA\n",
    "        start_time = time.time()\n",
    "        ma_qaoa = MultiAngleQAOA(edges, weights)\n",
    "        ma_result = ma_qaoa.optimize_parameters(layers=1, max_iterations=20)\n",
    "        ma_time = time.time() - start_time\n",
    "        \n",
    "        methods_data['multi_angle_qaoa']['costs'].append(-ma_result['optimal_value'])\n",
    "        methods_data['multi_angle_qaoa']['times'].append(ma_time)\n",
    "        \n",
    "        # Warm-Start QAOA\n",
    "        start_time = time.time()\n",
    "        ws_qaoa = WarmStartQAOA(edges, weights)\n",
    "        classical_init = ws_qaoa.greedy_maxcut()\n",
    "        ws_result = ws_qaoa.run_warm_qaoa(classical_init, layers=1)\n",
    "        ws_time = time.time() - start_time\n",
    "        \n",
    "        methods_data['warm_start_qaoa']['costs'].append(ws_result['qaoa_cost'])\n",
    "        methods_data['warm_start_qaoa']['times'].append(ws_time)\n",
    "    \n",
    "    # Visualization\n",
    "    plt.figure(figsize=(12, 5))\n",
    "    \n",
    "    # Performance scaling\n",
    "    plt.subplot(1, 2, 1)\n",
    "    colors = ['blue', 'green', 'orange']\n",
    "    for i, (method, data) in enumerate(methods_data.items()):\n",
    "        method_name = method.replace('_', ' ').title()\n",
    "        plt.plot(node_counts, data['costs'], 'o-', color=colors[i], label=method_name)\n",
    "    \n",
    "    plt.xlabel('Number of Nodes')\n",
    "    plt.ylabel('MaxCut Value')\n",
    "    plt.title('Performance vs Problem Size')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    # Time scaling\n",
    "    plt.subplot(1, 2, 2)\n",
    "    for i, (method, data) in enumerate(methods_data.items()):\n",
    "        method_name = method.replace('_', ' ').title()\n",
    "        plt.plot(node_counts, data['times'], 's-', color=colors[i], label=method_name)\n",
    "    \n",
    "    plt.xlabel('Number of Nodes')\n",
    "    plt.ylabel('Execution Time (s)')\n",
    "    plt.title('Runtime vs Problem Size')\n",
    "    plt.legend()\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    return methods_data\n",
    "\n",
    "# Run exercises\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"RUNNING EXERCISES\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "# Exercise 1\n",
    "sensitivity_results = parameter_sensitivity_analysis(test_edges, test_weights, n_trials=8)\n",
    "\n",
    "# Exercise 2  \n",
    "scaling_results = scaling_analysis(max_nodes=8)\n",
    "\n",
    "print(\"\\n✅ All exercises completed!\")\n",
    "print(\"\\n📝 Key Insights:\")\n",
    "print(f\"1. Parameter sensitivity: Multi-Angle QAOA std = {sensitivity_results['multi_angle']['std']:.3f} vs Standard = {sensitivity_results['standard']['std']:.3f}\")\n",
    "print(\"2. Scaling: Multi-Angle QAOA requires more parameters but often achieves better performance\")\n",
    "print(\"3. Warm-starting provides consistent improvements over classical initialization\")\n",
    "print(\"4. Recursive QAOA is most beneficial for larger, structured problems\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4db14569",
   "metadata": {},
   "source": [
    "## 📋 Summary\n",
    "\n",
    "### What We've Learned\n",
    "\n",
    "1. **Recursive QAOA (RQAOA)**:\n",
    "   - Breaks large problems into smaller pieces\n",
    "   - Often finds better solutions than standard QAOA\n",
    "   - Natural for divide-and-conquer problems\n",
    "\n",
    "2. **Multi-Angle QAOA**:\n",
    "   - Individual parameters for each constraint/qubit\n",
    "   - More flexible but exponentially more parameters\n",
    "   - Can capture problem structure better\n",
    "\n",
    "3. **Warm-Starting**:\n",
    "   - Initialize with classical solutions\n",
    "   - Faster convergence and better final solutions\n",
    "   - Combines classical intuition with quantum enhancement\n",
    "\n",
    "### Performance Trade-offs\n",
    "\n",
    "| Method | Pros | Cons |\n",
    "|--------|------|------|\n",
    "| Standard QAOA | Simple, few parameters | Limited expressivity |\n",
    "| Multi-Angle QAOA | High flexibility | Parameter explosion |\n",
    "| Warm-Start QAOA | Fast convergence | Depends on classical quality |\n",
    "| Recursive QAOA | Scales well | Requires confident variable identification |\n",
    "\n",
    "### When to Use Each Method\n",
    "\n",
    "- **Standard QAOA**: Small problems, initial exploration\n",
    "- **Multi-Angle QAOA**: Medium problems with structure\n",
    "- **Warm-Start QAOA**: When good classical heuristics exist\n",
    "- **Recursive QAOA**: Large problems with clear decomposition\n",
    "\n",
    "## 🎯 Next Steps\n",
    "\n",
    "1. **Hybrid Classical-Quantum Methods**: Combine the best of both worlds\n",
    "2. **Hardware-Efficient QAOA**: Adapt to specific quantum device constraints\n",
    "3. **Problem-Specific Optimizations**: Tailor methods to specific optimization problems\n",
    "4. **Error Mitigation**: Handle noise in NISQ devices\n",
    "\n",
    "### 🔬 Advanced Topics to Explore\n",
    "\n",
    "- Quantum error correction in optimization\n",
    "- Barren plateau mitigation strategies\n",
    "- Parameter initialization strategies\n",
    "- Problem decomposition techniques\n",
    "- Quantum advantage analysis\n",
    "\n",
    "---\n",
    "\n",
    "**Continue to the next notebook**: `../06_Hybrid_Approaches/01_Classical_Quantum_Integration.ipynb`"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
