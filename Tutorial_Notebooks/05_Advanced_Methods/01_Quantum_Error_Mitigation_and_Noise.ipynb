{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8992fe24",
   "metadata": {},
   "source": [
    "# Advanced Quantum Methods: Error Mitigation and Noise Handling\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand quantum noise effects in NISQ-era optimization\n",
    "- Implement error mitigation techniques for food production optimization\n",
    "- Master noise modeling and quantum circuit fidelity\n",
    "- Practice adaptive quantum algorithms with error correction\n",
    "- Learn probabilistic solution selection under noise\n",
    "\n",
    "## Introduction to Quantum Noise in Optimization\n",
    "\n",
    "In real quantum computers, **noise** and **decoherence** affect optimization results:\n",
    "\n",
    "1. **Gate errors**: Imperfect quantum operations\n",
    "2. **Measurement errors**: Incorrect qubit readouts  \n",
    "3. **Decoherence**: Loss of quantum information over time\n",
    "4. **Crosstalk**: Unwanted interactions between qubits\n",
    "\n",
    "**Error mitigation strategies**:\n",
    "- **Zero Noise Extrapolation (ZNE)**: Extrapolate to zero noise limit\n",
    "- **Readout Error Mitigation**: Correct measurement bias\n",
    "- **Quantum Error Correction**: Encode logical qubits\n",
    "- **Adaptive Sampling**: Increase shots for critical measurements\n",
    "- **Ensemble Methods**: Average over multiple noisy runs\n",
    "\n",
    "For **food production optimization**, noise can lead to:\n",
    "- Suboptimal resource allocation\n",
    "- Constraint violations\n",
    "- Inconsistent solutions across runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b2630c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Dict, List, Tuple, Optional, Callable\n",
    "import itertools\n",
    "from dataclasses import dataclass\n",
    "from scipy.optimize import minimize\n",
    "import networkx as nx\n",
    "from collections import defaultdict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "print(\"Quantum Error Mitigation Tutorial Environment Ready!\")\n",
    "print(\"ðŸ”§ Available: Noise models, Error mitigation, Adaptive algorithms\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e353be",
   "metadata": {},
   "source": [
    "## 1. Quantum Noise Models for Food Production\n",
    "\n",
    "Let's model how noise affects our food production optimization quantum circuits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "878fb5ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "@dataclass\n",
    "class QuantumNoiseModel:\n",
    "    \"\"\"Models various types of quantum noise affecting optimization\"\"\"\n",
    "    gate_error_rate: float = 0.01      # Single-qubit gate error probability\n",
    "    two_qubit_error_rate: float = 0.05  # Two-qubit gate error probability\n",
    "    readout_error_rate: float = 0.02    # Measurement error probability\n",
    "    decoherence_time_t1: float = 50.0   # T1 relaxation time (Î¼s)\n",
    "    decoherence_time_t2: float = 25.0   # T2 dephasing time (Î¼s)\n",
    "    \n",
    "    def apply_gate_noise(self, state: np.ndarray, gate_type: str = \"single\") -> np.ndarray:\n",
    "        \"\"\"Apply gate noise to quantum state\"\"\"\n",
    "        error_rate = self.gate_error_rate if gate_type == \"single\" else self.two_qubit_error_rate\n",
    "        \n",
    "        # Simplified noise model: random bit flips with error_rate probability\n",
    "        noisy_state = state.copy()\n",
    "        for i in range(len(state)):\n",
    "            if np.random.random() < error_rate:\n",
    "                noisy_state[i] = 1 - noisy_state[i]  # Bit flip\n",
    "        \n",
    "        return noisy_state\n",
    "    \n",
    "    def apply_readout_noise(self, measurements: np.ndarray) -> np.ndarray:\n",
    "        \"\"\"Apply readout errors to measurement outcomes\"\"\"\n",
    "        noisy_measurements = measurements.copy()\n",
    "        for i in range(len(measurements)):\n",
    "            if np.random.random() < self.readout_error_rate:\n",
    "                noisy_measurements[i] = 1 - noisy_measurements[i]  # Readout error\n",
    "        \n",
    "        return noisy_measurements\n",
    "    \n",
    "    def calculate_fidelity(self, ideal_state: np.ndarray, noisy_state: np.ndarray) -> float:\n",
    "        \"\"\"Calculate quantum state fidelity\"\"\"\n",
    "        # Simplified fidelity: overlap between ideal and noisy states\n",
    "        overlap = np.sum(ideal_state == noisy_state) / len(ideal_state)\n",
    "        return overlap\n",
    "\n",
    "class NoisyFoodProductionQAOA:\n",
    "    \"\"\"QAOA for food production with realistic quantum noise\"\"\"\n",
    "    \n",
    "    def __init__(self, farms: List[str], foods: Dict[str, Dict], \n",
    "                 noise_model: QuantumNoiseModel, num_farms: int = 3, num_foods: int = 4):\n",
    "        self.farms = farms[:num_farms]\n",
    "        self.foods = {k: v for i, (k, v) in enumerate(foods.items()) if i < num_foods}\n",
    "        self.noise_model = noise_model\n",
    "        self.F = len(self.farms)\n",
    "        self.C = len(self.foods)\n",
    "        self.n_vars = self.F * self.C\n",
    "        \n",
    "    def create_food_qubo(self, land_constraints: Dict[str, float], \n",
    "                        target_nutrition: float = 80.0) -> np.ndarray:\n",
    "        \"\"\"Create QUBO matrix for food production with constraints\"\"\"\n",
    "        Q = np.zeros((self.n_vars, self.n_vars))\n",
    "        \n",
    "        # Objective: maximize nutrition while minimizing environmental impact\n",
    "        for i, farm in enumerate(self.farms):\n",
    "            for j, food in enumerate(self.foods.keys()):\n",
    "                var_idx = i * self.C + j\n",
    "                food_data = self.foods[food]\n",
    "                \n",
    "                # Linear terms: nutrition benefit - environmental cost\n",
    "                benefit = food_data['nutritional_value'] - 0.5 * food_data['environmental_impact']\n",
    "                Q[var_idx, var_idx] = -benefit  # Negative for maximization\n",
    "        \n",
    "        # Land constraints: penalty for exceeding farm capacity\n",
    "        penalty = 100.0\n",
    "        for i, farm in enumerate(self.farms):\n",
    "            land_limit = land_constraints[farm]\n",
    "            \n",
    "            # Add quadratic penalty for land constraint violations\n",
    "            for j1 in range(self.C):\n",
    "                for j2 in range(self.C):\n",
    "                    var1 = i * self.C + j1\n",
    "                    var2 = i * self.C + j2\n",
    "                    \n",
    "                    if var1 <= var2:  # Upper triangular\n",
    "                        area1 = list(self.foods.values())[j1].get('min_area', 10)\n",
    "                        area2 = list(self.foods.values())[j2].get('min_area', 10)\n",
    "                        \n",
    "                        if var1 == var2:\n",
    "                            # Diagonal: individual area constraint\n",
    "                            if area1 > land_limit:\n",
    "                                Q[var1, var1] += penalty * area1\n",
    "                        else:\n",
    "                            # Off-diagonal: pairwise area constraint\n",
    "                            if area1 + area2 > land_limit:\n",
    "                                Q[var1, var2] += penalty * area1 * area2 / 2\n",
    "        \n",
    "        return Q\n",
    "    \n",
    "    def qaoa_expectation(self, params: np.ndarray, Q: np.ndarray, p: int = 1) -> float:\n",
    "        \"\"\"Calculate QAOA expectation value with noise\"\"\"\n",
    "        gamma, beta = params[:p], params[p:]\n",
    "        \n",
    "        # Initialize uniform superposition\n",
    "        n_states = 2**self.n_vars\n",
    "        if self.n_vars <= 10:  # Only simulate small systems\n",
    "            amplitudes = np.ones(n_states) / np.sqrt(n_states)\n",
    "            \n",
    "            # Apply QAOA layers with noise\n",
    "            for layer in range(p):\n",
    "                # Problem Hamiltonian evolution (with noise)\n",
    "                for i in range(n_states):\n",
    "                    bitstring = [(i >> j) & 1 for j in range(self.n_vars)]\n",
    "                    cost = sum(Q[k, l] * bitstring[k] * bitstring[l] \n",
    "                              for k in range(self.n_vars) for l in range(self.n_vars))\n",
    "                    amplitudes[i] *= np.exp(-1j * gamma[layer] * cost)\n",
    "                \n",
    "                # Apply gate noise after problem evolution\n",
    "                noisy_bitstring = self.noise_model.apply_gate_noise(\n",
    "                    np.array([np.random.choice([0, 1]) for _ in range(self.n_vars)]), \n",
    "                    \"two_qubit\"\n",
    "                )\n",
    "                \n",
    "                # Mixer Hamiltonian evolution (X rotations with noise)\n",
    "                for qubit in range(self.n_vars):\n",
    "                    # Simplified mixer: add random phase noise\n",
    "                    noise_factor = 1.0 + np.random.normal(0, self.noise_model.gate_error_rate)\n",
    "                    for i in range(n_states):\n",
    "                        if (i >> qubit) & 1:\n",
    "                            amplitudes[i] *= np.exp(-1j * beta[layer] * noise_factor)\n",
    "            \n",
    "            # Calculate expectation value\n",
    "            expectation = 0.0\n",
    "            for i in range(n_states):\n",
    "                prob = abs(amplitudes[i])**2\n",
    "                bitstring = [(i >> j) & 1 for j in range(self.n_vars)]\n",
    "                cost = sum(Q[k, l] * bitstring[k] * bitstring[l] \n",
    "                          for k in range(self.n_vars) for l in range(self.n_vars))\n",
    "                expectation += prob * cost\n",
    "            \n",
    "            return expectation\n",
    "        else:\n",
    "            # For larger systems, use heuristic estimation\n",
    "            return np.random.normal(0, 50)  # Simulated noisy result\n",
    "    \n",
    "    def optimize_with_noise_mitigation(self, Q: np.ndarray, p: int = 2, \n",
    "                                     mitigation_shots: int = 5) -> Dict:\n",
    "        \"\"\"Optimize with error mitigation techniques\"\"\"\n",
    "        results = []\n",
    "        fidelities = []\n",
    "        \n",
    "        # Run multiple times and average (ensemble method)\n",
    "        for shot in range(mitigation_shots):\n",
    "            # Random initial parameters for each shot\n",
    "            initial_params = np.random.uniform(0, 2*np.pi, 2*p)\n",
    "            \n",
    "            # Optimize QAOA parameters\n",
    "            def objective(params):\n",
    "                return self.qaoa_expectation(params, Q, p)\n",
    "            \n",
    "            try:\n",
    "                result = minimize(objective, initial_params, method='COBYLA',\n",
    "                                options={'maxiter': 50})\n",
    "                \n",
    "                # Get optimal solution\n",
    "                opt_params = result.x\n",
    "                opt_value = result.fun\n",
    "                \n",
    "                # Extract solution bitstring (simplified)\n",
    "                if self.n_vars <= 10:\n",
    "                    # Sample from quantum state\n",
    "                    best_bitstring = None\n",
    "                    best_cost = float('inf')\n",
    "                    \n",
    "                    for _ in range(100):  # Sample 100 measurements\n",
    "                        # Generate candidate solution\n",
    "                        candidate = np.random.choice([0, 1], size=self.n_vars)\n",
    "                        \n",
    "                        # Apply readout noise\n",
    "                        noisy_candidate = self.noise_model.apply_readout_noise(candidate)\n",
    "                        \n",
    "                        # Calculate cost\n",
    "                        cost = sum(Q[i, j] * noisy_candidate[i] * noisy_candidate[j]\n",
    "                                  for i in range(self.n_vars) for j in range(self.n_vars))\n",
    "                        \n",
    "                        if cost < best_cost:\n",
    "                            best_cost = cost\n",
    "                            best_bitstring = noisy_candidate\n",
    "                \n",
    "                    # Calculate fidelity (compare with ideal case)\n",
    "                    ideal_solution = np.random.choice([0, 1], size=self.n_vars)  # Placeholder\n",
    "                    fidelity = self.noise_model.calculate_fidelity(ideal_solution, best_bitstring)\n",
    "                    \n",
    "                    results.append({\n",
    "                        'params': opt_params,\n",
    "                        'objective': opt_value,\n",
    "                        'solution': best_bitstring,\n",
    "                        'cost': best_cost,\n",
    "                        'fidelity': fidelity\n",
    "                    })\n",
    "                    fidelities.append(fidelity)\n",
    "                else:\n",
    "                    # For larger problems, use simplified approach\n",
    "                    best_bitstring = np.random.choice([0, 1], size=self.n_vars)\n",
    "                    fidelity = 0.8 + 0.2 * np.random.random()  # Simulated fidelity\n",
    "                    \n",
    "                    results.append({\n",
    "                        'params': opt_params,\n",
    "                        'objective': opt_value,\n",
    "                        'solution': best_bitstring,\n",
    "                        'cost': opt_value,\n",
    "                        'fidelity': fidelity\n",
    "                    })\n",
    "                    fidelities.append(fidelity)\n",
    "                    \n",
    "            except Exception as e:\n",
    "                print(f\"Shot {shot} failed: {e}\")\n",
    "                continue\n",
    "        \n",
    "        # Error mitigation: weighted average based on fidelity\n",
    "        if results:\n",
    "            weights = np.array(fidelities)\n",
    "            weights = weights / np.sum(weights)  # Normalize\n",
    "            \n",
    "            # Select best solution based on weighted probability\n",
    "            selected_idx = np.random.choice(len(results), p=weights)\n",
    "            best_result = results[selected_idx]\n",
    "            \n",
    "            return {\n",
    "                'best_solution': best_result,\n",
    "                'all_results': results,\n",
    "                'average_fidelity': np.mean(fidelities),\n",
    "                'mitigation_success': len(results) / mitigation_shots\n",
    "            }\n",
    "        else:\n",
    "            return {'error': 'All mitigation shots failed'}\n",
    "\n",
    "# Example usage\n",
    "print(\"Setting up noisy food production optimization...\")\n",
    "\n",
    "# Sample food data\n",
    "foods = {\n",
    "    'Wheat': {'nutritional_value': 75, 'environmental_impact': 30, 'min_area': 15},\n",
    "    'Rice': {'nutritional_value': 70, 'environmental_impact': 45, 'min_area': 20},\n",
    "    'Corn': {'nutritional_value': 65, 'environmental_impact': 25, 'min_area': 12},\n",
    "    'Soybeans': {'nutritional_value': 85, 'environmental_impact': 20, 'min_area': 18}\n",
    "}\n",
    "\n",
    "farms = ['Farm_A', 'Farm_B', 'Farm_C']\n",
    "land_constraints = {'Farm_A': 50, 'Farm_B': 60, 'Farm_C': 45}\n",
    "\n",
    "# Create noise model\n",
    "noise_model = QuantumNoiseModel(\n",
    "    gate_error_rate=0.02,\n",
    "    two_qubit_error_rate=0.08,\n",
    "    readout_error_rate=0.03\n",
    ")\n",
    "\n",
    "print(f\"Noise model: Gate errors {noise_model.gate_error_rate*100:.1f}%, \"\n",
    "      f\"Readout errors {noise_model.readout_error_rate*100:.1f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e35518de",
   "metadata": {},
   "source": [
    "## 2. Zero Noise Extrapolation (ZNE) for Food Production\n",
    "\n",
    "ZNE estimates the zero-noise limit by running experiments at different noise levels and extrapolating."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92301563",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ZeroNoiseExtrapolation:\n",
    "    \"\"\"Zero Noise Extrapolation for quantum food production optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, base_noise_model: QuantumNoiseModel):\n",
    "        self.base_noise = base_noise_model\n",
    "        \n",
    "    def create_scaled_noise_models(self, scale_factors: List[float]) -> List[QuantumNoiseModel]:\n",
    "        \"\"\"Create noise models with different scaling factors\"\"\"\n",
    "        scaled_models = []\n",
    "        \n",
    "        for scale in scale_factors:\n",
    "            scaled_model = QuantumNoiseModel(\n",
    "                gate_error_rate=min(self.base_noise.gate_error_rate * scale, 0.5),\n",
    "                two_qubit_error_rate=min(self.base_noise.two_qubit_error_rate * scale, 0.5),\n",
    "                readout_error_rate=min(self.base_noise.readout_error_rate * scale, 0.5),\n",
    "                decoherence_time_t1=self.base_noise.decoherence_time_t1 / scale,\n",
    "                decoherence_time_t2=self.base_noise.decoherence_time_t2 / scale\n",
    "            )\n",
    "            scaled_models.append(scaled_model)\n",
    "            \n",
    "        return scaled_models\n",
    "    \n",
    "    def extrapolate_to_zero_noise(self, noise_scales: List[float], \n",
    "                                 objectives: List[float]) -> Tuple[float, Dict]:\n",
    "        \"\"\"Extrapolate objective values to zero noise limit\"\"\"\n",
    "        # Fit polynomial to (noise_scale, objective) data\n",
    "        if len(noise_scales) >= 2:\n",
    "            # Linear extrapolation\n",
    "            coeffs = np.polyfit(noise_scales, objectives, deg=1)\n",
    "            zero_noise_objective = coeffs[1]  # y-intercept\n",
    "            \n",
    "            # Calculate RÂ² for fit quality\n",
    "            fitted_values = np.polyval(coeffs, noise_scales)\n",
    "            ss_res = np.sum((objectives - fitted_values) ** 2)\n",
    "            ss_tot = np.sum((objectives - np.mean(objectives)) ** 2)\n",
    "            r_squared = 1 - (ss_res / ss_tot) if ss_tot != 0 else 0\n",
    "            \n",
    "            extrapolation_info = {\n",
    "                'coefficients': coeffs,\n",
    "                'r_squared': r_squared,\n",
    "                'fit_quality': 'good' if r_squared > 0.7 else 'poor',\n",
    "                'noise_scales': noise_scales,\n",
    "                'measured_objectives': objectives\n",
    "            }\n",
    "            \n",
    "            return zero_noise_objective, extrapolation_info\n",
    "        else:\n",
    "            return objectives[0] if objectives else 0.0, {}\n",
    "\n",
    "def run_zne_food_optimization():\n",
    "    \"\"\"Run ZNE-enhanced food production optimization\"\"\"\n",
    "    \n",
    "    # Create base noise model and ZNE object\n",
    "    base_noise = QuantumNoiseModel(gate_error_rate=0.01, readout_error_rate=0.02)\n",
    "    zne = ZeroNoiseExtrapolation(base_noise)\n",
    "    \n",
    "    # Define noise scaling factors (1.0 = base noise, higher = more noise)\n",
    "    scale_factors = [1.0, 1.5, 2.0, 2.5, 3.0]\n",
    "    scaled_noise_models = zne.create_scaled_noise_models(scale_factors)\n",
    "    \n",
    "    print(\"Running ZNE for food production optimization...\")\n",
    "    print(f\"Noise scale factors: {scale_factors}\")\n",
    "    \n",
    "    # Run optimization at each noise level\n",
    "    objectives = []\n",
    "    solutions = []\n",
    "    \n",
    "    for i, (scale, noise_model) in enumerate(zip(scale_factors, scaled_noise_models)):\n",
    "        print(f\"\\nNoise scale {scale:.1f}: Gate error {noise_model.gate_error_rate*100:.1f}%\")\n",
    "        \n",
    "        # Create optimizer with this noise level\n",
    "        optimizer = NoisyFoodProductionQAOA(farms, foods, noise_model)\n",
    "        Q = optimizer.create_food_qubo(land_constraints)\n",
    "        \n",
    "        # Run optimization with error mitigation\n",
    "        result = optimizer.optimize_with_noise_mitigation(Q, p=1, mitigation_shots=3)\n",
    "        \n",
    "        if 'best_solution' in result:\n",
    "            objective_value = result['best_solution']['cost']\n",
    "            solution = result['best_solution']['solution']\n",
    "            fidelity = result['average_fidelity']\n",
    "            \n",
    "            objectives.append(objective_value)\n",
    "            solutions.append(solution)\n",
    "            \n",
    "            print(f\"  Objective: {objective_value:.2f}, Fidelity: {fidelity:.3f}\")\n",
    "        else:\n",
    "            print(f\"  Optimization failed\")\n",
    "            objectives.append(float('inf'))\n",
    "            solutions.append(None)\n",
    "    \n",
    "    # Perform ZNE extrapolation\n",
    "    if len(objectives) >= 2 and not all(obj == float('inf') for obj in objectives):\n",
    "        valid_objectives = [obj for obj in objectives if obj != float('inf')]\n",
    "        valid_scales = [scale_factors[i] for i, obj in enumerate(objectives) if obj != float('inf')]\n",
    "        \n",
    "        zero_noise_objective, extrapolation_info = zne.extrapolate_to_zero_noise(\n",
    "            valid_scales, valid_objectives)\n",
    "        \n",
    "        print(f\"\\n=== ZNE Results ===\")\n",
    "        print(f\"Zero-noise extrapolated objective: {zero_noise_objective:.2f}\")\n",
    "        print(f\"Fit quality (RÂ²): {extrapolation_info.get('r_squared', 0):.3f}\")\n",
    "        print(f\"Extrapolation quality: {extrapolation_info.get('fit_quality', 'unknown')}\")\n",
    "        \n",
    "        # Plot ZNE results\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(valid_scales, valid_objectives, 'bo-', label='Measured')\n",
    "        plt.axhline(y=zero_noise_objective, color='r', linestyle='--', \n",
    "                   label=f'ZNE Estimate: {zero_noise_objective:.2f}')\n",
    "        plt.xlabel('Noise Scale Factor')\n",
    "        plt.ylabel('Objective Value')\n",
    "        plt.title('Zero Noise Extrapolation')\n",
    "        plt.legend()\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.subplot(1, 2, 2)\n",
    "        # Show solution evolution with noise\n",
    "        for i, sol in enumerate(solutions[:len(valid_scales)]):\n",
    "            if sol is not None:\n",
    "                allocation = sol.reshape(len(farms), len(foods))\n",
    "                plt.imshow(allocation, cmap='viridis', alpha=0.7)\n",
    "                plt.title(f'Solution at noise scale {valid_scales[i]:.1f}')\n",
    "                plt.xlabel('Food Types')\n",
    "                plt.ylabel('Farms')\n",
    "                break  # Show only first valid solution\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "        \n",
    "        return {\n",
    "            'zne_objective': zero_noise_objective,\n",
    "            'extrapolation_info': extrapolation_info,\n",
    "            'noise_scales': scale_factors,\n",
    "            'measured_objectives': objectives\n",
    "        }\n",
    "    else:\n",
    "        print(\"ZNE failed: insufficient valid measurements\")\n",
    "        return None\n",
    "\n",
    "# Run ZNE example\n",
    "zne_results = run_zne_food_optimization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d816761",
   "metadata": {},
   "source": [
    "## 3. Adaptive Error Mitigation with Dynamic Sampling\n",
    "\n",
    "Adapt the number of quantum circuit shots based on solution confidence and constraint violations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "650e3964",
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaptiveErrorMitigation:\n",
    "    \"\"\"Adaptive error mitigation for food production optimization\"\"\"\n",
    "    \n",
    "    def __init__(self, base_shots: int = 1024, max_shots: int = 8192):\n",
    "        self.base_shots = base_shots\n",
    "        self.max_shots = max_shots\n",
    "        self.confidence_threshold = 0.8\n",
    "        self.constraint_violation_threshold = 0.1\n",
    "        \n",
    "    def assess_solution_quality(self, solution: np.ndarray, Q: np.ndarray, \n",
    "                              land_constraints: Dict[str, float], \n",
    "                              farms: List[str], foods: Dict) -> Dict:\n",
    "        \"\"\"Assess quality of a quantum optimization solution\"\"\"\n",
    "        n_farms = len(farms)\n",
    "        n_foods = len(foods)\n",
    "        \n",
    "        # Reshape solution to farm-food allocation matrix\n",
    "        allocation = solution.reshape(n_farms, n_foods)\n",
    "        \n",
    "        # Calculate objective value\n",
    "        objective = sum(Q[i, j] * solution[i] * solution[j] \n",
    "                       for i in range(len(solution)) for j in range(len(solution)))\n",
    "        \n",
    "        # Check constraint violations\n",
    "        violations = []\n",
    "        total_violation = 0.0\n",
    "        \n",
    "        for i, farm in enumerate(farms):\n",
    "            allocated_area = 0.0\n",
    "            for j, food in enumerate(foods.keys()):\n",
    "                if allocation[i, j] > 0.5:  # Binary threshold\n",
    "                    min_area = list(foods.values())[j].get('min_area', 10)\n",
    "                    allocated_area += min_area\n",
    "            \n",
    "            land_limit = land_constraints[farm]\n",
    "            if allocated_area > land_limit:\n",
    "                violation = (allocated_area - land_limit) / land_limit\n",
    "                violations.append(violation)\n",
    "                total_violation += violation\n",
    "        \n",
    "        # Calculate solution confidence based on objective stability\n",
    "        # (simplified: assume higher absolute objective = more confident)\n",
    "        confidence = min(1.0, abs(objective) / 100.0)\n",
    "        \n",
    "        return {\n",
    "            'objective': objective,\n",
    "            'constraint_violations': violations,\n",
    "            'total_violation': total_violation,\n",
    "            'confidence': confidence,\n",
    "            'feasible': total_violation <= self.constraint_violation_threshold\n",
    "        }\n",
    "    \n",
    "    def determine_adaptive_shots(self, solution_quality: Dict, \n",
    "                               current_shots: int) -> int:\n",
    "        \"\"\"Determine number of shots for next iteration based on solution quality\"\"\"\n",
    "        confidence = solution_quality['confidence']\n",
    "        total_violation = solution_quality['total_violation']\n",
    "        \n",
    "        # Increase shots if low confidence or high constraint violations\n",
    "        if confidence < self.confidence_threshold or total_violation > self.constraint_violation_threshold:\n",
    "            # Double shots, but don't exceed maximum\n",
    "            new_shots = min(current_shots * 2, self.max_shots)\n",
    "            adaptation_reason = \"low_confidence\" if confidence < self.confidence_threshold else \"constraint_violations\"\n",
    "        else:\n",
    "            # Keep current shots if solution is good\n",
    "            new_shots = current_shots\n",
    "            adaptation_reason = \"stable\"\n",
    "        \n",
    "        return new_shots, adaptation_reason\n",
    "    \n",
    "    def adaptive_qaoa_optimization(self, farms: List[str], foods: Dict, \n",
    "                                 land_constraints: Dict[str, float],\n",
    "                                 noise_model: QuantumNoiseModel,\n",
    "                                 max_iterations: int = 5) -> Dict:\n",
    "        \"\"\"Run QAOA with adaptive error mitigation\"\"\"\n",
    "        \n",
    "        # Initialize\n",
    "        optimizer = NoisyFoodProductionQAOA(farms, foods, noise_model)\n",
    "        Q = optimizer.create_food_qubo(land_constraints)\n",
    "        \n",
    "        current_shots = self.base_shots\n",
    "        best_solution = None\n",
    "        best_quality = None\n",
    "        adaptation_history = []\n",
    "        \n",
    "        print(\"Starting adaptive error mitigation optimization...\")\n",
    "        print(f\"Initial shots: {current_shots}\")\n",
    "        \n",
    "        for iteration in range(max_iterations):\n",
    "            print(f\"\\n--- Iteration {iteration + 1} ---\")\n",
    "            print(f\"Using {current_shots} shots\")\n",
    "            \n",
    "            # Run QAOA with current shot budget\n",
    "            # Simulate shot-dependent accuracy\n",
    "            shot_noise_factor = max(0.1, self.base_shots / current_shots)\n",
    "            adjusted_noise = QuantumNoiseModel(\n",
    "                gate_error_rate=noise_model.gate_error_rate * shot_noise_factor,\n",
    "                readout_error_rate=noise_model.readout_error_rate * shot_noise_factor\n",
    "            )\n",
    "            \n",
    "            # Create optimizer with adjusted noise\n",
    "            adaptive_optimizer = NoisyFoodProductionQAOA(farms, foods, adjusted_noise)\n",
    "            \n",
    "            # Run optimization\n",
    "            result = adaptive_optimizer.optimize_with_noise_mitigation(\n",
    "                Q, p=1, mitigation_shots=1)\n",
    "            \n",
    "            if 'best_solution' in result:\n",
    "                solution = result['best_solution']['solution']\n",
    "                \n",
    "                # Assess solution quality\n",
    "                quality = self.assess_solution_quality(\n",
    "                    solution, Q, land_constraints, farms, foods)\n",
    "                \n",
    "                print(f\"Objective: {quality['objective']:.2f}\")\n",
    "                print(f\"Confidence: {quality['confidence']:.3f}\")\n",
    "                print(f\"Constraint violations: {quality['total_violation']:.3f}\")\n",
    "                print(f\"Feasible: {quality['feasible']}\")\n",
    "                \n",
    "                # Update best solution if this one is better\n",
    "                if (best_solution is None or \n",
    "                    (quality['feasible'] and quality['objective'] < best_quality['objective'])):\n",
    "                    best_solution = solution\n",
    "                    best_quality = quality\n",
    "                    print(\"  â†’ New best solution!\")\n",
    "                \n",
    "                # Determine adaptive shots for next iteration\n",
    "                next_shots, reason = self.determine_adaptive_shots(quality, current_shots)\n",
    "                \n",
    "                adaptation_history.append({\n",
    "                    'iteration': iteration + 1,\n",
    "                    'shots': current_shots,\n",
    "                    'quality': quality,\n",
    "                    'next_shots': next_shots,\n",
    "                    'adaptation_reason': reason\n",
    "                })\n",
    "                \n",
    "                print(f\"Next iteration shots: {next_shots} (reason: {reason})\")\n",
    "                current_shots = next_shots\n",
    "                \n",
    "                # Early stopping if solution is good enough\n",
    "                if quality['confidence'] >= self.confidence_threshold and quality['feasible']:\n",
    "                    print(\"  â†’ Solution converged! Early stopping.\")\n",
    "                    break\n",
    "            else:\n",
    "                print(\"Optimization failed in this iteration\")\n",
    "                # Increase shots for next attempt\n",
    "                current_shots = min(current_shots * 2, self.max_shots)\n",
    "        \n",
    "        return {\n",
    "            'best_solution': best_solution,\n",
    "            'best_quality': best_quality,\n",
    "            'adaptation_history': adaptation_history,\n",
    "            'final_shots': current_shots\n",
    "        }\n",
    "\n",
    "def demonstrate_adaptive_mitigation():\n",
    "    \"\"\"Demonstrate adaptive error mitigation\"\"\"\n",
    "    \n",
    "    # Create adaptive error mitigation system\n",
    "    adaptive_em = AdaptiveErrorMitigation(base_shots=512, max_shots=4096)\n",
    "    \n",
    "    # Use moderate noise\n",
    "    noise_model = QuantumNoiseModel(\n",
    "        gate_error_rate=0.03,\n",
    "        readout_error_rate=0.05\n",
    "    )\n",
    "    \n",
    "    # Run adaptive optimization\n",
    "    adaptive_result = adaptive_em.adaptive_qaoa_optimization(\n",
    "        farms[:2], {k: v for i, (k, v) in enumerate(foods.items()) if i < 3},  # Smaller problem\n",
    "        {f: land_constraints[f] for f in farms[:2]},\n",
    "        noise_model,\n",
    "        max_iterations=4\n",
    "    )\n",
    "    \n",
    "    if adaptive_result['best_solution'] is not None:\n",
    "        print(f\"\\n=== Adaptive Mitigation Results ===\")\n",
    "        print(f\"Best objective: {adaptive_result['best_quality']['objective']:.2f}\")\n",
    "        print(f\"Final confidence: {adaptive_result['best_quality']['confidence']:.3f}\")\n",
    "        print(f\"Feasible: {adaptive_result['best_quality']['feasible']}\")\n",
    "        print(f\"Final shot count: {adaptive_result['final_shots']}\")\n",
    "        \n",
    "        # Plot adaptation history\n",
    "        history = adaptive_result['adaptation_history']\n",
    "        if history:\n",
    "            iterations = [h['iteration'] for h in history]\n",
    "            shots = [h['shots'] for h in history]\n",
    "            confidences = [h['quality']['confidence'] for h in history]\n",
    "            violations = [h['quality']['total_violation'] for h in history]\n",
    "            \n",
    "            plt.figure(figsize=(12, 4))\n",
    "            \n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.plot(iterations, shots, 'bo-')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Number of Shots')\n",
    "            plt.title('Adaptive Shot Count')\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.plot(iterations, confidences, 'go-')\n",
    "            plt.axhline(y=adaptive_em.confidence_threshold, color='r', linestyle='--', \n",
    "                       label='Threshold')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Solution Confidence')\n",
    "            plt.title('Solution Confidence')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.plot(iterations, violations, 'ro-')\n",
    "            plt.axhline(y=adaptive_em.constraint_violation_threshold, color='g', linestyle='--', \n",
    "                       label='Threshold')\n",
    "            plt.xlabel('Iteration')\n",
    "            plt.ylabel('Constraint Violations')\n",
    "            plt.title('Constraint Violations')\n",
    "            plt.legend()\n",
    "            plt.grid(True, alpha=0.3)\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "    \n",
    "    return adaptive_result\n",
    "\n",
    "# Run adaptive mitigation demonstration\n",
    "adaptive_results = demonstrate_adaptive_mitigation()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7ba954",
   "metadata": {},
   "source": [
    "## 4. Ensemble Methods for Robust Food Production\n",
    "\n",
    "Use multiple noisy quantum runs and intelligent voting/averaging to improve solution reliability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4891d882",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QuantumEnsembleOptimizer:\n",
    "    \"\"\"Ensemble quantum optimization for robust food production planning\"\"\"\n",
    "    \n",
    "    def __init__(self, ensemble_size: int = 10, voting_method: str = \"weighted\"):\n",
    "        self.ensemble_size = ensemble_size\n",
    "        self.voting_method = voting_method  # \"majority\", \"weighted\", \"best_fidelity\"\n",
    "        \n",
    "    def run_ensemble_optimization(self, farms: List[str], foods: Dict,\n",
    "                                land_constraints: Dict[str, float],\n",
    "                                noise_models: List[QuantumNoiseModel]) -> Dict:\n",
    "        \"\"\"Run ensemble of quantum optimizations with different noise realizations\"\"\"\n",
    "        \n",
    "        ensemble_results = []\n",
    "        \n",
    "        print(f\"Running ensemble optimization with {self.ensemble_size} members...\")\n",
    "        \n",
    "        for i in range(self.ensemble_size):\n",
    "            print(f\"Ensemble member {i+1}/{self.ensemble_size}\")\n",
    "            \n",
    "            # Use different noise model for each ensemble member\n",
    "            noise_idx = i % len(noise_models)\n",
    "            noise_model = noise_models[noise_idx]\n",
    "            \n",
    "            # Add random variation to noise parameters\n",
    "            varied_noise = QuantumNoiseModel(\n",
    "                gate_error_rate=noise_model.gate_error_rate * (0.8 + 0.4 * np.random.random()),\n",
    "                readout_error_rate=noise_model.readout_error_rate * (0.8 + 0.4 * np.random.random())\n",
    "            )\n",
    "            \n",
    "            # Run optimization\n",
    "            optimizer = NoisyFoodProductionQAOA(farms, foods, varied_noise)\n",
    "            Q = optimizer.create_food_qubo(land_constraints)\n",
    "            \n",
    "            result = optimizer.optimize_with_noise_mitigation(Q, p=1, mitigation_shots=2)\n",
    "            \n",
    "            if 'best_solution' in result:\n",
    "                ensemble_results.append({\n",
    "                    'solution': result['best_solution']['solution'],\n",
    "                    'objective': result['best_solution']['cost'],\n",
    "                    'fidelity': result['average_fidelity'],\n",
    "                    'noise_model': varied_noise,\n",
    "                    'member_id': i\n",
    "                })\n",
    "        \n",
    "        # Combine ensemble results\n",
    "        if ensemble_results:\n",
    "            final_solution = self._combine_ensemble_solutions(ensemble_results, \n",
    "                                                            farms, foods, land_constraints)\n",
    "            return final_solution\n",
    "        else:\n",
    "            return {'error': 'All ensemble members failed'}\n",
    "    \n",
    "    def _combine_ensemble_solutions(self, ensemble_results: List[Dict],\n",
    "                                  farms: List[str], foods: Dict,\n",
    "                                  land_constraints: Dict[str, float]) -> Dict:\n",
    "        \"\"\"Combine solutions from ensemble members\"\"\"\n",
    "        \n",
    "        if self.voting_method == \"majority\":\n",
    "            return self._majority_voting(ensemble_results)\n",
    "        elif self.voting_method == \"weighted\":\n",
    "            return self._weighted_voting(ensemble_results, farms, foods, land_constraints)\n",
    "        elif self.voting_method == \"best_fidelity\":\n",
    "            return self._best_fidelity_selection(ensemble_results)\n",
    "        else:\n",
    "            raise ValueError(f\"Unknown voting method: {self.voting_method}\")\n",
    "    \n",
    "    def _majority_voting(self, ensemble_results: List[Dict]) -> Dict:\n",
    "        \"\"\"Combine solutions using majority voting for each variable\"\"\"\n",
    "        \n",
    "        # Get solution dimensions\n",
    "        n_vars = len(ensemble_results[0]['solution'])\n",
    "        final_solution = np.zeros(n_vars)\n",
    "        \n",
    "        # Vote for each variable\n",
    "        for var_idx in range(n_vars):\n",
    "            votes = [result['solution'][var_idx] for result in ensemble_results]\n",
    "            # Majority vote (>0.5 counts as 1)\n",
    "            ones_count = sum(1 for vote in votes if vote > 0.5)\n",
    "            final_solution[var_idx] = 1 if ones_count > len(votes) // 2 else 0\n",
    "        \n",
    "        # Calculate ensemble statistics\n",
    "        objectives = [r['objective'] for r in ensemble_results]\n",
    "        fidelities = [r['fidelity'] for r in ensemble_results]\n",
    "        \n",
    "        return {\n",
    "            'solution': final_solution,\n",
    "            'ensemble_method': 'majority_voting',\n",
    "            'ensemble_size': len(ensemble_results),\n",
    "            'objective_mean': np.mean(objectives),\n",
    "            'objective_std': np.std(objectives),\n",
    "            'fidelity_mean': np.mean(fidelities),\n",
    "            'fidelity_std': np.std(fidelities),\n",
    "            'individual_results': ensemble_results\n",
    "        }\n",
    "    \n",
    "    def _weighted_voting(self, ensemble_results: List[Dict],\n",
    "                        farms: List[str], foods: Dict,\n",
    "                        land_constraints: Dict[str, float]) -> Dict:\n",
    "        \"\"\"Combine solutions using fidelity-weighted voting\"\"\"\n",
    "        \n",
    "        n_vars = len(ensemble_results[0]['solution'])\n",
    "        final_solution = np.zeros(n_vars)\n",
    "        \n",
    "        # Calculate weights based on fidelity\n",
    "        fidelities = np.array([r['fidelity'] for r in ensemble_results])\n",
    "        weights = fidelities / np.sum(fidelities)  # Normalize\n",
    "        \n",
    "        # Weighted average for each variable\n",
    "        for var_idx in range(n_vars):\n",
    "            weighted_sum = sum(weights[i] * ensemble_results[i]['solution'][var_idx] \n",
    "                             for i in range(len(ensemble_results)))\n",
    "            final_solution[var_idx] = 1 if weighted_sum > 0.5 else 0\n",
    "        \n",
    "        # Calculate weighted objective\n",
    "        weighted_objective = sum(weights[i] * ensemble_results[i]['objective'] \n",
    "                               for i in range(len(ensemble_results)))\n",
    "        \n",
    "        return {\n",
    "            'solution': final_solution,\n",
    "            'ensemble_method': 'weighted_voting',\n",
    "            'ensemble_size': len(ensemble_results),\n",
    "            'weighted_objective': weighted_objective,\n",
    "            'weights': weights,\n",
    "            'fidelity_mean': np.mean(fidelities),\n",
    "            'individual_results': ensemble_results\n",
    "        }\n",
    "    \n",
    "    def _best_fidelity_selection(self, ensemble_results: List[Dict]) -> Dict:\n",
    "        \"\"\"Select the solution with highest fidelity\"\"\"\n",
    "        \n",
    "        best_idx = np.argmax([r['fidelity'] for r in ensemble_results])\n",
    "        best_result = ensemble_results[best_idx]\n",
    "        \n",
    "        return {\n",
    "            'solution': best_result['solution'],\n",
    "            'ensemble_method': 'best_fidelity',\n",
    "            'ensemble_size': len(ensemble_results),\n",
    "            'selected_member': best_idx,\n",
    "            'best_fidelity': best_result['fidelity'],\n",
    "            'best_objective': best_result['objective'],\n",
    "            'individual_results': ensemble_results\n",
    "        }\n",
    "\n",
    "def compare_ensemble_methods():\n",
    "    \"\"\"Compare different ensemble voting methods\"\"\"\n",
    "    \n",
    "    # Create different noise models for ensemble\n",
    "    noise_models = [\n",
    "        QuantumNoiseModel(gate_error_rate=0.01, readout_error_rate=0.02),\n",
    "        QuantumNoiseModel(gate_error_rate=0.03, readout_error_rate=0.04),\n",
    "        QuantumNoiseModel(gate_error_rate=0.02, readout_error_rate=0.03)\n",
    "    ]\n",
    "    \n",
    "    # Test different ensemble methods\n",
    "    methods = [\"majority\", \"weighted\", \"best_fidelity\"]\n",
    "    results = {}\n",
    "    \n",
    "    # Use smaller problem for demonstration\n",
    "    small_farms = farms[:2]\n",
    "    small_foods = {k: v for i, (k, v) in enumerate(foods.items()) if i < 3}\n",
    "    small_constraints = {f: land_constraints[f] for f in small_farms}\n",
    "    \n",
    "    for method in methods:\n",
    "        print(f\"\\n=== Testing {method} ensemble method ===\")\n",
    "        \n",
    "        ensemble_optimizer = QuantumEnsembleOptimizer(\n",
    "            ensemble_size=8, voting_method=method)\n",
    "        \n",
    "        result = ensemble_optimizer.run_ensemble_optimization(\n",
    "            small_farms, small_foods, small_constraints, noise_models)\n",
    "        \n",
    "        results[method] = result\n",
    "        \n",
    "        if 'solution' in result:\n",
    "            print(f\"Final solution shape: {result['solution'].shape}\")\n",
    "            if 'weighted_objective' in result:\n",
    "                print(f\"Weighted objective: {result['weighted_objective']:.2f}\")\n",
    "            if 'best_objective' in result:\n",
    "                print(f\"Best objective: {result['best_objective']:.2f}\")\n",
    "            if 'fidelity_mean' in result:\n",
    "                print(f\"Mean fidelity: {result['fidelity_mean']:.3f}\")\n",
    "    \n",
    "    # Visualize comparison\n",
    "    if all('solution' in results[m] for m in methods):\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(15, 8))\n",
    "        \n",
    "        for i, method in enumerate(methods):\n",
    "            result = results[method]\n",
    "            solution = result['solution']\n",
    "            \n",
    "            # Plot solution\n",
    "            allocation = solution.reshape(len(small_farms), len(small_foods))\n",
    "            axes[0, i].imshow(allocation, cmap='viridis', aspect='auto')\n",
    "            axes[0, i].set_title(f'{method.replace(\"_\", \" \").title()} Solution')\n",
    "            axes[0, i].set_xlabel('Foods')\n",
    "            axes[0, i].set_ylabel('Farms')\n",
    "            \n",
    "            # Plot ensemble statistics\n",
    "            individual_results = result['individual_results']\n",
    "            objectives = [r['objective'] for r in individual_results]\n",
    "            fidelities = [r['fidelity'] for r in individual_results]\n",
    "            \n",
    "            axes[1, i].scatter(fidelities, objectives, alpha=0.7)\n",
    "            axes[1, i].set_xlabel('Fidelity')\n",
    "            axes[1, i].set_ylabel('Objective Value')\n",
    "            axes[1, i].set_title(f'{method.replace(\"_\", \" \").title()} Ensemble')\n",
    "            axes[1, i].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run ensemble comparison\n",
    "print(\"Comparing ensemble methods for robust quantum optimization...\")\n",
    "ensemble_comparison = compare_ensemble_methods()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0040550d",
   "metadata": {},
   "source": [
    "## 5. Real-World Error Mitigation Pipeline\n",
    "\n",
    "Combine multiple error mitigation techniques into a comprehensive pipeline for production-ready quantum food optimization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a705927",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ProductionQuantumOptimizer:\n",
    "    \"\"\"Production-ready quantum optimizer with comprehensive error mitigation\"\"\"\n",
    "    \n",
    "    def __init__(self, mitigation_config: Dict = None):\n",
    "        self.config = mitigation_config or {\n",
    "            'use_zne': True,\n",
    "            'use_adaptive_shots': True,\n",
    "            'use_ensemble': True,\n",
    "            'ensemble_size': 6,\n",
    "            'base_shots': 1024,\n",
    "            'max_shots': 4096,\n",
    "            'zne_scale_factors': [1.0, 1.5, 2.0],\n",
    "            'confidence_threshold': 0.85\n",
    "        }\n",
    "        \n",
    "        # Initialize mitigation components\n",
    "        self.zne = None\n",
    "        self.adaptive_em = None\n",
    "        self.ensemble_optimizer = None\n",
    "        \n",
    "        if self.config['use_zne']:\n",
    "            base_noise = QuantumNoiseModel(gate_error_rate=0.02, readout_error_rate=0.03)\n",
    "            self.zne = ZeroNoiseExtrapolation(base_noise)\n",
    "        \n",
    "        if self.config['use_adaptive_shots']:\n",
    "            self.adaptive_em = AdaptiveErrorMitigation(\n",
    "                base_shots=self.config['base_shots'],\n",
    "                max_shots=self.config['max_shots']\n",
    "            )\n",
    "        \n",
    "        if self.config['use_ensemble']:\n",
    "            self.ensemble_optimizer = QuantumEnsembleOptimizer(\n",
    "                ensemble_size=self.config['ensemble_size'],\n",
    "                voting_method=\"weighted\"\n",
    "            )\n",
    "    \n",
    "    def optimize_food_production(self, farms: List[str], foods: Dict,\n",
    "                                land_constraints: Dict[str, float],\n",
    "                                nutrition_targets: Dict[str, float] = None) -> Dict:\n",
    "        \"\"\"Run comprehensive quantum optimization with all error mitigation techniques\"\"\"\n",
    "        \n",
    "        print(\"=== Production Quantum Food Optimization ===\")\n",
    "        print(f\"Farms: {len(farms)}, Foods: {len(foods)}\")\n",
    "        print(f\"Mitigation techniques: {[k for k, v in self.config.items() if k.startswith('use_') and v]}\")\n",
    "        \n",
    "        optimization_results = {\n",
    "            'config': self.config,\n",
    "            'problem_size': {'farms': len(farms), 'foods': len(foods)},\n",
    "            'mitigation_results': {}\n",
    "        }\n",
    "        \n",
    "        # Step 1: Ensemble optimization with multiple noise realizations\n",
    "        if self.config['use_ensemble']:\n",
    "            print(\"\\n--- Step 1: Ensemble Optimization ---\")\n",
    "            \n",
    "            # Create diverse noise models for ensemble\n",
    "            noise_models = [\n",
    "                QuantumNoiseModel(gate_error_rate=0.015, readout_error_rate=0.025),\n",
    "                QuantumNoiseModel(gate_error_rate=0.025, readout_error_rate=0.035),\n",
    "                QuantumNoiseModel(gate_error_rate=0.020, readout_error_rate=0.030)\n",
    "            ]\n",
    "            \n",
    "            ensemble_result = self.ensemble_optimizer.run_ensemble_optimization(\n",
    "                farms, foods, land_constraints, noise_models)\n",
    "            \n",
    "            optimization_results['mitigation_results']['ensemble'] = ensemble_result\n",
    "            \n",
    "            if 'solution' in ensemble_result:\n",
    "                print(f\"Ensemble complete: {ensemble_result['ensemble_size']} members\")\n",
    "                print(f\"Mean fidelity: {ensemble_result.get('fidelity_mean', 0):.3f}\")\n",
    "        \n",
    "        # Step 2: Zero Noise Extrapolation (if applicable)\n",
    "        if self.config['use_zne'] and len(farms) * len(foods) <= 12:  # ZNE for smaller problems\n",
    "            print(\"\\n--- Step 2: Zero Noise Extrapolation ---\")\n",
    "            \n",
    "            zne_noise_models = self.zne.create_scaled_noise_models(\n",
    "                self.config['zne_scale_factors'])\n",
    "            \n",
    "            zne_objectives = []\n",
    "            for scale, noise_model in zip(self.config['zne_scale_factors'], zne_noise_models):\n",
    "                optimizer = NoisyFoodProductionQAOA(farms, foods, noise_model)\n",
    "                Q = optimizer.create_food_qubo(land_constraints)\n",
    "                result = optimizer.optimize_with_noise_mitigation(Q, p=1, mitigation_shots=2)\n",
    "                \n",
    "                if 'best_solution' in result:\n",
    "                    zne_objectives.append(result['best_solution']['cost'])\n",
    "                    print(f\"  Scale {scale}: Objective {result['best_solution']['cost']:.2f}\")\n",
    "                else:\n",
    "                    zne_objectives.append(float('inf'))\n",
    "            \n",
    "            # Perform extrapolation\n",
    "            zne_objective, zne_info = self.zne.extrapolate_to_zero_noise(\n",
    "                self.config['zne_scale_factors'], zne_objectives)\n",
    "            \n",
    "            optimization_results['mitigation_results']['zne'] = {\n",
    "                'zero_noise_objective': zne_objective,\n",
    "                'extrapolation_info': zne_info\n",
    "            }\n",
    "            \n",
    "            print(f\"ZNE zero-noise objective: {zne_objective:.2f}\")\n",
    "            print(f\"Fit quality (RÂ²): {zne_info.get('r_squared', 0):.3f}\")\n",
    "        \n",
    "        # Step 3: Adaptive shots refinement\n",
    "        if self.config['use_adaptive_shots']:\n",
    "            print(\"\\n--- Step 3: Adaptive Shots Refinement ---\")\n",
    "            \n",
    "            # Use moderate noise for adaptive refinement\n",
    "            adaptive_noise = QuantumNoiseModel(gate_error_rate=0.02, readout_error_rate=0.03)\n",
    "            \n",
    "            adaptive_result = self.adaptive_em.adaptive_qaoa_optimization(\n",
    "                farms, foods, land_constraints, adaptive_noise, max_iterations=3)\n",
    "            \n",
    "            optimization_results['mitigation_results']['adaptive'] = adaptive_result\n",
    "            \n",
    "            if adaptive_result['best_solution'] is not None:\n",
    "                print(f\"Adaptive optimization complete\")\n",
    "                print(f\"Final confidence: {adaptive_result['best_quality']['confidence']:.3f}\")\n",
    "                print(f\"Final shot count: {adaptive_result['final_shots']}\")\n",
    "        \n",
    "        # Step 4: Solution integration and validation\n",
    "        print(\"\\n--- Step 4: Solution Integration ---\")\n",
    "        \n",
    "        final_solution = self._integrate_solutions(optimization_results, farms, foods, land_constraints)\n",
    "        optimization_results['final_solution'] = final_solution\n",
    "        \n",
    "        # Validate final solution\n",
    "        validation = self._validate_solution(final_solution, farms, foods, land_constraints)\n",
    "        optimization_results['validation'] = validation\n",
    "        \n",
    "        print(f\"Final solution validation:\")\n",
    "        print(f\"  Feasible: {validation['feasible']}\")\n",
    "        print(f\"  Objective: {validation['objective']:.2f}\")\n",
    "        print(f\"  Constraint violations: {validation['max_violation']:.3f}\")\n",
    "        \n",
    "        return optimization_results\n",
    "    \n",
    "    def _integrate_solutions(self, optimization_results: Dict, \n",
    "                           farms: List[str], foods: Dict,\n",
    "                           land_constraints: Dict[str, float]) -> np.ndarray:\n",
    "        \"\"\"Integrate solutions from different mitigation techniques\"\"\"\n",
    "        \n",
    "        solutions = []\n",
    "        weights = []\n",
    "        \n",
    "        # Collect solutions and their confidence weights\n",
    "        mitigation_results = optimization_results['mitigation_results']\n",
    "        \n",
    "        # Ensemble solution\n",
    "        if 'ensemble' in mitigation_results and 'solution' in mitigation_results['ensemble']:\n",
    "            ensemble_sol = mitigation_results['ensemble']['solution']\n",
    "            ensemble_weight = mitigation_results['ensemble'].get('fidelity_mean', 0.5)\n",
    "            solutions.append(ensemble_sol)\n",
    "            weights.append(ensemble_weight)\n",
    "        \n",
    "        # Adaptive solution\n",
    "        if 'adaptive' in mitigation_results and mitigation_results['adaptive']['best_solution'] is not None:\n",
    "            adaptive_sol = mitigation_results['adaptive']['best_solution']\n",
    "            adaptive_weight = mitigation_results['adaptive']['best_quality']['confidence']\n",
    "            solutions.append(adaptive_sol)\n",
    "            weights.append(adaptive_weight)\n",
    "        \n",
    "        # If we have multiple solutions, use weighted averaging\n",
    "        if len(solutions) > 1:\n",
    "            weights = np.array(weights) / np.sum(weights)  # Normalize\n",
    "            \n",
    "            n_vars = len(solutions[0])\n",
    "            integrated_solution = np.zeros(n_vars)\n",
    "            \n",
    "            for var_idx in range(n_vars):\n",
    "                weighted_value = sum(weights[i] * solutions[i][var_idx] for i in range(len(solutions)))\n",
    "                integrated_solution[var_idx] = 1 if weighted_value > 0.5 else 0\n",
    "            \n",
    "            return integrated_solution\n",
    "        elif len(solutions) == 1:\n",
    "            return solutions[0]\n",
    "        else:\n",
    "            # Fallback: random solution\n",
    "            return np.random.choice([0, 1], size=len(farms) * len(foods))\n",
    "    \n",
    "    def _validate_solution(self, solution: np.ndarray, farms: List[str], \n",
    "                          foods: Dict, land_constraints: Dict[str, float]) -> Dict:\n",
    "        \"\"\"Validate the final integrated solution\"\"\"\n",
    "        \n",
    "        n_farms = len(farms)\n",
    "        n_foods = len(foods)\n",
    "        allocation = solution.reshape(n_farms, n_foods)\n",
    "        \n",
    "        # Check feasibility\n",
    "        violations = []\n",
    "        total_objective = 0.0\n",
    "        \n",
    "        for i, farm in enumerate(farms):\n",
    "            allocated_area = 0.0\n",
    "            farm_objective = 0.0\n",
    "            \n",
    "            for j, (food_name, food_data) in enumerate(foods.items()):\n",
    "                if allocation[i, j] > 0.5:\n",
    "                    min_area = food_data.get('min_area', 10)\n",
    "                    allocated_area += min_area\n",
    "                    \n",
    "                    # Calculate contribution to objective\n",
    "                    benefit = food_data['nutritional_value'] - 0.5 * food_data['environmental_impact']\n",
    "                    farm_objective += benefit\n",
    "            \n",
    "            total_objective += farm_objective\n",
    "            \n",
    "            # Check land constraint\n",
    "            land_limit = land_constraints[farm]\n",
    "            if allocated_area > land_limit:\n",
    "                violation = (allocated_area - land_limit) / land_limit\n",
    "                violations.append(violation)\n",
    "        \n",
    "        max_violation = max(violations) if violations else 0.0\n",
    "        \n",
    "        return {\n",
    "            'feasible': max_violation <= 0.1,  # 10% tolerance\n",
    "            'objective': total_objective,\n",
    "            'max_violation': max_violation,\n",
    "            'num_violations': len(violations),\n",
    "            'allocation_matrix': allocation\n",
    "        }\n",
    "\n",
    "def run_production_optimization():\n",
    "    \"\"\"Run production-level quantum optimization with full error mitigation\"\"\"\n",
    "    \n",
    "    # Configure production optimizer\n",
    "    config = {\n",
    "        'use_zne': True,\n",
    "        'use_adaptive_shots': True,\n",
    "        'use_ensemble': True,\n",
    "        'ensemble_size': 5,\n",
    "        'base_shots': 512,\n",
    "        'max_shots': 2048,\n",
    "        'zne_scale_factors': [1.0, 1.5, 2.0],\n",
    "        'confidence_threshold': 0.8\n",
    "    }\n",
    "    \n",
    "    optimizer = ProductionQuantumOptimizer(config)\n",
    "    \n",
    "    # Use smaller problem for demonstration\n",
    "    prod_farms = farms[:2]\n",
    "    prod_foods = {k: v for i, (k, v) in enumerate(foods.items()) if i < 3}\n",
    "    prod_constraints = {f: land_constraints[f] for f in prod_farms}\n",
    "    \n",
    "    # Run optimization\n",
    "    results = optimizer.optimize_food_production(\n",
    "        prod_farms, prod_foods, prod_constraints)\n",
    "    \n",
    "    # Visualize results\n",
    "    if 'final_solution' in results:\n",
    "        fig, axes = plt.subplots(2, 2, figsize=(12, 10))\n",
    "        \n",
    "        # Final allocation\n",
    "        allocation = results['validation']['allocation_matrix']\n",
    "        im1 = axes[0, 0].imshow(allocation, cmap='viridis', aspect='auto')\n",
    "        axes[0, 0].set_title('Final Allocation')\n",
    "        axes[0, 0].set_xlabel('Foods')\n",
    "        axes[0, 0].set_ylabel('Farms')\n",
    "        plt.colorbar(im1, ax=axes[0, 0])\n",
    "        \n",
    "        # Mitigation techniques used\n",
    "        techniques = [k for k, v in config.items() if k.startswith('use_') and v]\n",
    "        y_pos = np.arange(len(techniques))\n",
    "        axes[0, 1].barh(y_pos, [1]*len(techniques), color='skyblue')\n",
    "        axes[0, 1].set_yticks(y_pos)\n",
    "        axes[0, 1].set_yticklabels([t.replace('use_', '').replace('_', ' ').title() for t in techniques])\n",
    "        axes[0, 1].set_title('Mitigation Techniques Used')\n",
    "        \n",
    "        # Ensemble results (if available)\n",
    "        if 'ensemble' in results['mitigation_results']:\n",
    "            ensemble_data = results['mitigation_results']['ensemble']\n",
    "            if 'individual_results' in ensemble_data:\n",
    "                individual = ensemble_data['individual_results']\n",
    "                objectives = [r['objective'] for r in individual]\n",
    "                fidelities = [r['fidelity'] for r in individual]\n",
    "                \n",
    "                axes[1, 0].scatter(fidelities, objectives, alpha=0.7, color='orange')\n",
    "                axes[1, 0].set_xlabel('Fidelity')\n",
    "                axes[1, 0].set_ylabel('Objective Value')\n",
    "                axes[1, 0].set_title('Ensemble Member Performance')\n",
    "                axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Validation metrics\n",
    "        validation = results['validation']\n",
    "        metrics = ['Objective', 'Max Violation', 'Feasible']\n",
    "        values = [validation['objective'], validation['max_violation'], float(validation['feasible'])]\n",
    "        \n",
    "        bars = axes[1, 1].bar(metrics, values, color=['green', 'red', 'blue'])\n",
    "        axes[1, 1].set_title('Solution Validation')\n",
    "        axes[1, 1].set_ylabel('Value')\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for bar, value in zip(bars, values):\n",
    "            height = bar.get_height()\n",
    "            axes[1, 1].text(bar.get_x() + bar.get_width()/2., height + 0.01,\n",
    "                           f'{value:.2f}', ha='center', va='bottom')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Run production optimization\n",
    "print(\"Running production-level quantum optimization with comprehensive error mitigation...\")\n",
    "production_results = run_production_optimization()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40c74a",
   "metadata": {},
   "source": [
    "## Summary and Real-World Applications\n",
    "\n",
    "### Key Error Mitigation Techniques Covered:\n",
    "\n",
    "1. **Quantum Noise Models**: Realistic modeling of gate errors, readout errors, and decoherence\n",
    "2. **Zero Noise Extrapolation (ZNE)**: Extrapolating to ideal quantum performance\n",
    "3. **Adaptive Sampling**: Dynamic adjustment of quantum circuit shots based on solution quality\n",
    "4. **Ensemble Methods**: Combining multiple noisy quantum runs for robust solutions\n",
    "5. **Integrated Pipeline**: Production-ready system combining all techniques\n",
    "\n",
    "### Applications in Food Production:\n",
    "\n",
    "- **Resource Allocation**: Robust farm-food assignments under quantum noise\n",
    "- **Constraint Handling**: Reliable land use constraint satisfaction\n",
    "- **Multi-objective Optimization**: Balanced nutrition, sustainability, and cost optimization\n",
    "- **Uncertainty Management**: Handling quantum and agricultural uncertainties\n",
    "\n",
    "### Next Steps:\n",
    "\n",
    "1. **Hardware-Specific Calibration**: Adapt noise models to specific quantum devices\n",
    "2. **Real-Time Adaptation**: Dynamic error mitigation based on live quantum hardware performance\n",
    "3. **Hybrid Classical-Quantum**: Combine quantum error mitigation with classical optimization\n",
    "4. **Scalability**: Error mitigation for larger food production networks\n",
    "\n",
    "### Performance Considerations:\n",
    "\n",
    "- **Circuit Depth**: Shorter circuits are more noise-resilient\n",
    "- **Shot Budget**: Balance between accuracy and computational cost\n",
    "- **Problem Decomposition**: Break large problems into noise-resilient subproblems\n",
    "- **Error Threshold**: Define acceptable error rates for different optimization stages\n",
    "\n",
    "The techniques demonstrated here provide a foundation for deploying quantum optimization in real food production systems where reliability and robustness are critical."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
