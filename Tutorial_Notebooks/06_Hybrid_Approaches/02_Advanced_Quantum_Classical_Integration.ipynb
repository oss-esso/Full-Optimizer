{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a1b37d5",
   "metadata": {},
   "source": [
    "## 5. Quantum-Inspired Classical Algorithms\n",
    "\n",
    "Quantum-inspired classical algorithms leverage quantum principles to enhance classical optimization without requiring actual quantum hardware. These algorithms are particularly valuable for bridging the gap between classical and quantum approaches."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "748cf1ee",
   "metadata": {},
   "source": [
    "### 5.1 Quantum-Inspired Annealing\n",
    "\n",
    "Quantum annealing-inspired classical algorithms use the concept of quantum tunneling and superposition to escape local minima more effectively than traditional simulated annealing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2f52a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from typing import Callable, Tuple, List\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class QuantumInspiredAnnealingParams:\n",
    "    \"\"\"Parameters for quantum-inspired annealing.\"\"\"\n",
    "    initial_temp: float = 1000.0\n",
    "    final_temp: float = 0.01\n",
    "    cooling_rate: float = 0.95\n",
    "    max_iterations: int = 10000\n",
    "    tunneling_strength: float = 0.1\n",
    "    coherence_time: int = 100\n",
    "    num_parallel_chains: int = 8\n",
    "    \n",
    "class QuantumInspiredAnnealer:\n",
    "    \"\"\"Quantum-inspired annealing for combinatorial optimization.\"\"\"\n",
    "    \n",
    "    def __init__(self, params: QuantumInspiredAnnealingParams):\n",
    "        self.params = params\n",
    "        self.energy_history = []\n",
    "        self.temperature_history = []\n",
    "        \n",
    "    def quantum_tunneling_probability(self, delta_energy: float, temperature: float, \n",
    "                                    tunneling_strength: float) -> float:\n",
    "        \"\"\"\n",
    "        Calculate quantum tunneling probability inspired by quantum mechanics.\n",
    "        \n",
    "        Args:\n",
    "            delta_energy: Energy difference\n",
    "            temperature: Current temperature\n",
    "            tunneling_strength: Strength of quantum tunneling effect\n",
    "            \n",
    "        Returns:\n",
    "            Probability of accepting the move\n",
    "        \"\"\"\n",
    "        # Classical Boltzmann factor\n",
    "        classical_prob = np.exp(-delta_energy / temperature) if delta_energy > 0 else 1.0\n",
    "        \n",
    "        # Quantum tunneling enhancement\n",
    "        if delta_energy > 0:\n",
    "            # Quantum tunneling allows escaping energy barriers\n",
    "            tunneling_prob = tunneling_strength * np.exp(-delta_energy / (2 * temperature))\n",
    "            return min(1.0, classical_prob + tunneling_prob)\n",
    "        else:\n",
    "            return 1.0\n",
    "    \n",
    "    def generate_superposition_moves(self, current_solution: List[int], \n",
    "                                   num_moves: int = 5) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Generate multiple candidate moves inspired by quantum superposition.\n",
    "        \n",
    "        Args:\n",
    "            current_solution: Current solution state\n",
    "            num_moves: Number of candidate moves to generate\n",
    "            \n",
    "        Returns:\n",
    "            List of candidate solutions\n",
    "        \"\"\"\n",
    "        candidates = []\n",
    "        n = len(current_solution)\n",
    "        \n",
    "        for _ in range(num_moves):\n",
    "            candidate = current_solution.copy()\n",
    "            \n",
    "            # Generate different types of moves\n",
    "            move_type = random.choice(['single_flip', 'double_flip', 'swap', 'block_flip'])\n",
    "            \n",
    "            if move_type == 'single_flip':\n",
    "                # Single bit flip\n",
    "                idx = random.randint(0, n-1)\n",
    "                candidate[idx] = 1 - candidate[idx]\n",
    "                \n",
    "            elif move_type == 'double_flip':\n",
    "                # Two bit flips\n",
    "                idx1, idx2 = random.sample(range(n), 2)\n",
    "                candidate[idx1] = 1 - candidate[idx1]\n",
    "                candidate[idx2] = 1 - candidate[idx2]\n",
    "                \n",
    "            elif move_type == 'swap':\n",
    "                # Swap two positions\n",
    "                idx1, idx2 = random.sample(range(n), 2)\n",
    "                candidate[idx1], candidate[idx2] = candidate[idx2], candidate[idx1]\n",
    "                \n",
    "            elif move_type == 'block_flip':\n",
    "                # Flip a block of bits\n",
    "                block_size = min(random.randint(2, 5), n//2)\n",
    "                start_idx = random.randint(0, n - block_size)\n",
    "                for i in range(start_idx, start_idx + block_size):\n",
    "                    candidate[i] = 1 - candidate[i]\n",
    "            \n",
    "            candidates.append(candidate)\n",
    "        \n",
    "        return candidates\n",
    "    \n",
    "    def parallel_chain_evolution(self, objective_func: Callable, \n",
    "                               initial_solutions: List[List[int]]) -> Tuple[List[int], float]:\n",
    "        \"\"\"\n",
    "        Evolve multiple parallel chains inspired by quantum parallelism.\n",
    "        \n",
    "        Args:\n",
    "            objective_func: Objective function to minimize\n",
    "            initial_solutions: List of initial solutions for parallel chains\n",
    "            \n",
    "        Returns:\n",
    "            Best solution found and its energy\n",
    "        \"\"\"\n",
    "        num_chains = len(initial_solutions)\n",
    "        current_solutions = [sol.copy() for sol in initial_solutions]\n",
    "        current_energies = [objective_func(sol) for sol in current_solutions]\n",
    "        \n",
    "        best_solution = min(current_solutions, key=objective_func)\n",
    "        best_energy = objective_func(best_solution)\n",
    "        \n",
    "        temperature = self.params.initial_temp\n",
    "        \n",
    "        for iteration in range(self.params.max_iterations):\n",
    "            # Update temperature\n",
    "            temperature *= self.params.cooling_rate\n",
    "            temperature = max(temperature, self.params.final_temp)\n",
    "            \n",
    "            # Evolve each chain\n",
    "            for chain_idx in range(num_chains):\n",
    "                # Generate candidate moves\n",
    "                candidates = self.generate_superposition_moves(\n",
    "                    current_solutions[chain_idx], \n",
    "                    num_moves=3\n",
    "                )\n",
    "                \n",
    "                # Evaluate candidates\n",
    "                for candidate in candidates:\n",
    "                    candidate_energy = objective_func(candidate)\n",
    "                    delta_energy = candidate_energy - current_energies[chain_idx]\n",
    "                    \n",
    "                    # Apply quantum-inspired acceptance probability\n",
    "                    accept_prob = self.quantum_tunneling_probability(\n",
    "                        delta_energy, temperature, self.params.tunneling_strength\n",
    "                    )\n",
    "                    \n",
    "                    if random.random() < accept_prob:\n",
    "                        current_solutions[chain_idx] = candidate\n",
    "                        current_energies[chain_idx] = candidate_energy\n",
    "                        \n",
    "                        # Update global best\n",
    "                        if candidate_energy < best_energy:\n",
    "                            best_solution = candidate.copy()\n",
    "                            best_energy = candidate_energy\n",
    "            \n",
    "            # Quantum entanglement-inspired information exchange\n",
    "            if iteration % self.params.coherence_time == 0 and iteration > 0:\n",
    "                self.perform_chain_entanglement(current_solutions, current_energies, \n",
    "                                              objective_func, temperature)\n",
    "            \n",
    "            # Record progress\n",
    "            if iteration % 100 == 0:\n",
    "                self.energy_history.append(best_energy)\n",
    "                self.temperature_history.append(temperature)\n",
    "                \n",
    "                if iteration % 1000 == 0:\n",
    "                    print(f\"Iteration {iteration}: Best Energy = {best_energy:.4f}, \"\n",
    "                          f\"Temperature = {temperature:.6f}\")\n",
    "        \n",
    "        return best_solution, best_energy\n",
    "    \n",
    "    def perform_chain_entanglement(self, solutions: List[List[int]], \n",
    "                                 energies: List[float],\n",
    "                                 objective_func: Callable,\n",
    "                                 temperature: float):\n",
    "        \"\"\"\n",
    "        Perform information exchange between chains inspired by quantum entanglement.\n",
    "        \n",
    "        Args:\n",
    "            solutions: Current solutions for each chain\n",
    "            energies: Current energies for each chain\n",
    "            objective_func: Objective function\n",
    "            temperature: Current temperature\n",
    "        \"\"\"\n",
    "        num_chains = len(solutions)\n",
    "        \n",
    "        # Find best and worst performing chains\n",
    "        best_idx = np.argmin(energies)\n",
    "        worst_idx = np.argmax(energies)\n",
    "        \n",
    "        # Create hybrid solutions by combining information\n",
    "        for i in range(num_chains):\n",
    "            if i != best_idx and random.random() < 0.3:  # 30% chance of entanglement\n",
    "                # Create hybrid solution\n",
    "                hybrid = solutions[i].copy()\n",
    "                n = len(hybrid)\n",
    "                \n",
    "                # Copy random segments from best solution\n",
    "                segment_length = random.randint(1, n//4)\n",
    "                start_pos = random.randint(0, n - segment_length)\n",
    "                \n",
    "                for j in range(start_pos, start_pos + segment_length):\n",
    "                    hybrid[j] = solutions[best_idx][j]\n",
    "                \n",
    "                # Evaluate hybrid\n",
    "                hybrid_energy = objective_func(hybrid)\n",
    "                delta_energy = hybrid_energy - energies[i]\n",
    "                \n",
    "                # Accept based on quantum-inspired probability\n",
    "                accept_prob = self.quantum_tunneling_probability(\n",
    "                    delta_energy, temperature, self.params.tunneling_strength * 0.5\n",
    "                )\n",
    "                \n",
    "                if random.random() < accept_prob:\n",
    "                    solutions[i] = hybrid\n",
    "                    energies[i] = hybrid_energy\n",
    "    \n",
    "    def optimize(self, objective_func: Callable, problem_size: int) -> Tuple[List[int], float]:\n",
    "        \"\"\"\n",
    "        Main optimization method.\n",
    "        \n",
    "        Args:\n",
    "            objective_func: Objective function to minimize\n",
    "            problem_size: Size of the problem (number of variables)\n",
    "            \n",
    "        Returns:\n",
    "            Best solution and its objective value\n",
    "        \"\"\"\n",
    "        # Initialize parallel chains with diverse starting points\n",
    "        initial_solutions = []\n",
    "        for _ in range(self.params.num_parallel_chains):\n",
    "            solution = [random.randint(0, 1) for _ in range(problem_size)]\n",
    "            initial_solutions.append(solution)\n",
    "        \n",
    "        # Run optimization\n",
    "        best_solution, best_energy = self.parallel_chain_evolution(\n",
    "            objective_func, initial_solutions\n",
    "        )\n",
    "        \n",
    "        return best_solution, best_energy\n",
    "    \n",
    "    def plot_convergence(self):\n",
    "        \"\"\"Plot optimization convergence.\"\"\"\n",
    "        fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(12, 8))\n",
    "        \n",
    "        # Energy convergence\n",
    "        ax1.plot(self.energy_history, 'b-', linewidth=2)\n",
    "        ax1.set_xlabel('Iteration (×100)')\n",
    "        ax1.set_ylabel('Best Energy')\n",
    "        ax1.set_title('Quantum-Inspired Annealing: Energy Convergence')\n",
    "        ax1.grid(True, alpha=0.3)\n",
    "        \n",
    "        # Temperature schedule\n",
    "        ax2.semilogy(self.temperature_history, 'r-', linewidth=2)\n",
    "        ax2.set_xlabel('Iteration (×100)')\n",
    "        ax2.set_ylabel('Temperature (log scale)')\n",
    "        ax2.set_title('Temperature Schedule')\n",
    "        ax2.grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "print(\"Quantum-Inspired Annealing implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9b5451e",
   "metadata": {},
   "source": [
    "### 5.2 Quantum Amplitude Amplification Inspired Search\n",
    "\n",
    "This algorithm is inspired by Grover's quantum search algorithm and quantum amplitude amplification, using iterative improvement to amplify the probability of finding good solutions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d67293e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from typing import List, Callable, Tuple\n",
    "import random\n",
    "from collections import defaultdict\n",
    "\n",
    "class QuantumAmplitudeSearch:\n",
    "    \"\"\"Quantum amplitude amplification inspired search algorithm.\"\"\"\n",
    "    \n",
    "    def __init__(self, amplification_rounds: int = 10, population_size: int = 100,\n",
    "                 selection_ratio: float = 0.2, mutation_strength: float = 0.1):\n",
    "        self.amplification_rounds = amplification_rounds\n",
    "        self.population_size = population_size\n",
    "        self.selection_ratio = selection_ratio\n",
    "        self.mutation_strength = mutation_strength\n",
    "        self.fitness_history = []\n",
    "        \n",
    "    def initialize_population(self, problem_size: int) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Initialize population with diverse solutions.\n",
    "        \n",
    "        Args:\n",
    "            problem_size: Number of variables in the problem\n",
    "            \n",
    "        Returns:\n",
    "            Initial population\n",
    "        \"\"\"\n",
    "        population = []\n",
    "        \n",
    "        # Add completely random solutions\n",
    "        for _ in range(self.population_size // 2):\n",
    "            solution = [random.randint(0, 1) for _ in range(problem_size)]\n",
    "            population.append(solution)\n",
    "        \n",
    "        # Add structured solutions\n",
    "        for _ in range(self.population_size // 4):\n",
    "            # Solutions with blocks of 1s and 0s\n",
    "            solution = [0] * problem_size\n",
    "            block_size = random.randint(1, problem_size // 4)\n",
    "            start_pos = random.randint(0, problem_size - block_size)\n",
    "            for i in range(start_pos, start_pos + block_size):\n",
    "                solution[i] = 1\n",
    "            population.append(solution)\n",
    "        \n",
    "        # Add alternating patterns\n",
    "        for _ in range(self.population_size // 4):\n",
    "            pattern = random.choice([0, 1])\n",
    "            period = random.randint(2, 8)\n",
    "            solution = [(i // period + pattern) % 2 for i in range(problem_size)]\n",
    "            population.append(solution)\n",
    "        \n",
    "        return population\n",
    "    \n",
    "    def oracle_function(self, solution: List[int], objective_func: Callable, \n",
    "                       threshold: float) -> bool:\n",
    "        \"\"\"\n",
    "        Oracle function that marks 'good' solutions (inspired by Grover's oracle).\n",
    "        \n",
    "        Args:\n",
    "            solution: Candidate solution\n",
    "            objective_func: Objective function to evaluate\n",
    "            threshold: Threshold for considering a solution 'good'\n",
    "            \n",
    "        Returns:\n",
    "            True if solution is marked as 'good'\n",
    "        \"\"\"\n",
    "        energy = objective_func(solution)\n",
    "        return energy <= threshold\n",
    "    \n",
    "    def amplitude_amplification(self, population: List[List[int]], \n",
    "                              objective_func: Callable,\n",
    "                              current_best_energy: float) -> List[List[int]]:\n",
    "        \"\"\"\n",
    "        Perform amplitude amplification on the population.\n",
    "        \n",
    "        Args:\n",
    "            population: Current population\n",
    "            objective_func: Objective function\n",
    "            current_best_energy: Current best energy for threshold setting\n",
    "            \n",
    "        Returns:\n",
    "            Amplified population with higher concentration of good solutions\n",
    "        \"\"\"\n",
    "        # Set threshold for 'good' solutions\n",
    "        threshold = current_best_energy + 0.1 * abs(current_best_energy)\n",
    "        \n",
    "        # Evaluate all solutions\n",
    "        evaluations = [(sol, objective_func(sol)) for sol in population]\n",
    "        evaluations.sort(key=lambda x: x[1])  # Sort by energy\n",
    "        \n",
    "        # Mark good solutions\n",
    "        good_solutions = [sol for sol, energy in evaluations if energy <= threshold]\n",
    "        bad_solutions = [sol for sol, energy in evaluations if energy > threshold]\n",
    "        \n",
    "        # Amplitude amplification inspired selection\n",
    "        amplified_population = []\n",
    "        \n",
    "        # Heavily sample from good solutions (amplitude amplification)\n",
    "        if good_solutions:\n",
    "            good_sample_size = min(len(good_solutions) * 3, self.population_size // 2)\n",
    "            for _ in range(good_sample_size):\n",
    "                solution = random.choice(good_solutions).copy()\n",
    "                # Add small mutations to create diversity\n",
    "                solution = self.apply_quantum_mutation(solution)\n",
    "                amplified_population.append(solution)\n",
    "        \n",
    "        # Inversion about average (diffusion operator)\n",
    "        if len(amplified_population) < self.population_size:\n",
    "            # Create combinations of good solutions\n",
    "            for _ in range(self.population_size - len(amplified_population)):\n",
    "                if len(good_solutions) >= 2:\n",
    "                    # Quantum-inspired recombination\n",
    "                    parent1, parent2 = random.sample(good_solutions, 2)\n",
    "                    child = self.quantum_crossover(parent1, parent2)\n",
    "                    amplified_population.append(child)\n",
    "                else:\n",
    "                    # Fallback to mutation of existing solutions\n",
    "                    if good_solutions:\n",
    "                        parent = random.choice(good_solutions)\n",
    "                    else:\n",
    "                        parent = random.choice(population)\n",
    "                    child = self.apply_quantum_mutation(parent.copy())\n",
    "                    amplified_population.append(child)\n",
    "        \n",
    "        return amplified_population[:self.population_size]\n",
    "    \n",
    "    def apply_quantum_mutation(self, solution: List[int]) -> List[int]:\n",
    "        \"\"\"\n",
    "        Apply quantum-inspired mutations to a solution.\n",
    "        \n",
    "        Args:\n",
    "            solution: Solution to mutate\n",
    "            \n",
    "        Returns:\n",
    "            Mutated solution\n",
    "        \"\"\"\n",
    "        mutated = solution.copy()\n",
    "        n = len(solution)\n",
    "        \n",
    "        # Quantum-inspired mutation patterns\n",
    "        mutation_type = random.choice(['single', 'coherent', 'entangled'])\n",
    "        \n",
    "        if mutation_type == 'single':\n",
    "            # Single qubit rotation (bit flip)\n",
    "            if random.random() < self.mutation_strength:\n",
    "                idx = random.randint(0, n-1)\n",
    "                mutated[idx] = 1 - mutated[idx]\n",
    "                \n",
    "        elif mutation_type == 'coherent':\n",
    "            # Coherent rotation of multiple qubits\n",
    "            num_flips = max(1, int(n * self.mutation_strength * 0.5))\n",
    "            indices = random.sample(range(n), num_flips)\n",
    "            for idx in indices:\n",
    "                mutated[idx] = 1 - mutated[idx]\n",
    "                \n",
    "        elif mutation_type == 'entangled':\n",
    "            # Entangled mutations (correlated flips)\n",
    "            if random.random() < self.mutation_strength:\n",
    "                # Flip pairs of qubits\n",
    "                for _ in range(max(1, n // 10)):\n",
    "                    idx1, idx2 = random.sample(range(n), 2)\n",
    "                    if random.random() < 0.5:\n",
    "                        mutated[idx1] = 1 - mutated[idx1]\n",
    "                        mutated[idx2] = 1 - mutated[idx2]\n",
    "        \n",
    "        return mutated\n",
    "    \n",
    "    def quantum_crossover(self, parent1: List[int], parent2: List[int]) -> List[int]:\n",
    "        \"\"\"\n",
    "        Quantum-inspired crossover operation.\n",
    "        \n",
    "        Args:\n",
    "            parent1: First parent solution\n",
    "            parent2: Second parent solution\n",
    "            \n",
    "        Returns:\n",
    "            Child solution\n",
    "        \"\"\"\n",
    "        n = len(parent1)\n",
    "        child = [0] * n\n",
    "        \n",
    "        # Quantum superposition-inspired crossover\n",
    "        for i in range(n):\n",
    "            if parent1[i] == parent2[i]:\n",
    "                # Consensus: keep the common value\n",
    "                child[i] = parent1[i]\n",
    "            else:\n",
    "                # Superposition: random choice with bias toward better parent\n",
    "                child[i] = random.choice([parent1[i], parent2[i]])\n",
    "        \n",
    "        return child\n",
    "    \n",
    "    def optimize(self, objective_func: Callable, problem_size: int) -> Tuple[List[int], float]:\n",
    "        \"\"\"\n",
    "        Main optimization method using quantum amplitude amplification principles.\n",
    "        \n",
    "        Args:\n",
    "            objective_func: Objective function to minimize\n",
    "            problem_size: Size of the problem\n",
    "            \n",
    "        Returns:\n",
    "            Best solution and its objective value\n",
    "        \"\"\"\n",
    "        # Initialize population\n",
    "        population = self.initialize_population(problem_size)\n",
    "        \n",
    "        # Track best solution\n",
    "        best_solution = None\n",
    "        best_energy = float('inf')\n",
    "        \n",
    "        for round_num in range(self.amplification_rounds):\n",
    "            # Evaluate population\n",
    "            for solution in population:\n",
    "                energy = objective_func(solution)\n",
    "                if energy < best_energy:\n",
    "                    best_energy = energy\n",
    "                    best_solution = solution.copy()\n",
    "            \n",
    "            # Record progress\n",
    "            self.fitness_history.append(best_energy)\n",
    "            \n",
    "            print(f\"Round {round_num + 1}: Best Energy = {best_energy:.4f}\")\n",
    "            \n",
    "            # Apply amplitude amplification\n",
    "            if round_num < self.amplification_rounds - 1:  # Don't amplify on last round\n",
    "                population = self.amplitude_amplification(\n",
    "                    population, objective_func, best_energy\n",
    "                )\n",
    "        \n",
    "        return best_solution, best_energy\n",
    "    \n",
    "    def plot_convergence(self):\n",
    "        \"\"\"Plot optimization convergence.\"\"\"\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.plot(self.fitness_history, 'g-', linewidth=2, marker='o')\n",
    "        plt.xlabel('Amplification Round')\n",
    "        plt.ylabel('Best Fitness')\n",
    "        plt.title('Quantum Amplitude Amplification Inspired Search: Convergence')\n",
    "        plt.grid(True, alpha=0.3)\n",
    "        plt.show()\n",
    "\n",
    "print(\"Quantum Amplitude Amplification inspired search implementation complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94b68d85",
   "metadata": {},
   "source": [
    "### 5.3 Example: Comparing Quantum-Inspired Algorithms\n",
    "\n",
    "Let's test both quantum-inspired algorithms on a sample optimization problem and compare their performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "299ce9e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define test problem: Max-Cut on a random graph\n",
    "import networkx as nx\n",
    "import time\n",
    "\n",
    "def create_test_problem(n_nodes: int = 20, edge_probability: float = 0.3) -> Tuple[nx.Graph, Callable]:\n",
    "    \"\"\"\n",
    "    Create a Max-Cut test problem.\n",
    "    \n",
    "    Args:\n",
    "        n_nodes: Number of nodes in the graph\n",
    "        edge_probability: Probability of edge between any two nodes\n",
    "        \n",
    "    Returns:\n",
    "        Graph and objective function\n",
    "    \"\"\"\n",
    "    # Create random graph\n",
    "    np.random.seed(42)  # For reproducibility\n",
    "    G = nx.erdos_renyi_graph(n_nodes, edge_probability, seed=42)\n",
    "    \n",
    "    # Ensure graph is connected\n",
    "    if not nx.is_connected(G):\n",
    "        # Add edges to make it connected\n",
    "        components = list(nx.connected_components(G))\n",
    "        for i in range(len(components) - 1):\n",
    "            node1 = list(components[i])[0]\n",
    "            node2 = list(components[i + 1])[0]\n",
    "            G.add_edge(node1, node2)\n",
    "    \n",
    "    # Add random weights to edges\n",
    "    for u, v in G.edges():\n",
    "        G[u][v]['weight'] = np.random.uniform(0.5, 2.0)\n",
    "    \n",
    "    def maxcut_objective(solution: List[int]) -> float:\n",
    "        \"\"\"\n",
    "        Calculate Max-Cut objective (we minimize the negative cut value).\n",
    "        \n",
    "        Args:\n",
    "            solution: Binary assignment of nodes to partitions\n",
    "            \n",
    "        Returns:\n",
    "            Negative cut value (for minimization)\n",
    "        \"\"\"\n",
    "        cut_value = 0\n",
    "        for u, v in G.edges():\n",
    "            if solution[u] != solution[v]:  # Edge crosses the cut\n",
    "                cut_value += G[u][v]['weight']\n",
    "        return -cut_value  # Negative because we're minimizing\n",
    "    \n",
    "    return G, maxcut_objective\n",
    "\n",
    "# Create test problem\n",
    "test_graph, test_objective = create_test_problem(n_nodes=15, edge_probability=0.4)\n",
    "print(f\"Created test graph with {test_graph.number_of_nodes()} nodes and {test_graph.number_of_edges()} edges\")\n",
    "\n",
    "# Test Quantum-Inspired Annealing\n",
    "print(\"\\n=== Testing Quantum-Inspired Annealing ===\")\n",
    "qa_params = QuantumInspiredAnnealingParams(\n",
    "    initial_temp=100.0,\n",
    "    final_temp=0.01,\n",
    "    cooling_rate=0.98,\n",
    "    max_iterations=5000,\n",
    "    tunneling_strength=0.15,\n",
    "    coherence_time=200,\n",
    "    num_parallel_chains=6\n",
    ")\n",
    "\n",
    "qa_solver = QuantumInspiredAnnealer(qa_params)\n",
    "start_time = time.time()\n",
    "qa_solution, qa_energy = qa_solver.optimize(test_objective, test_graph.number_of_nodes())\n",
    "qa_time = time.time() - start_time\n",
    "\n",
    "print(f\"Quantum-Inspired Annealing Results:\")\n",
    "print(f\"  Best Energy: {qa_energy:.4f}\")\n",
    "print(f\"  Cut Value: {-qa_energy:.4f}\")\n",
    "print(f\"  Time: {qa_time:.2f} seconds\")\n",
    "print(f\"  Solution: {qa_solution}\")\n",
    "\n",
    "# Test Quantum Amplitude Search\n",
    "print(\"\\n=== Testing Quantum Amplitude Search ===\")\n",
    "qas_solver = QuantumAmplitudeSearch(\n",
    "    amplification_rounds=15,\n",
    "    population_size=80,\n",
    "    selection_ratio=0.25,\n",
    "    mutation_strength=0.12\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "qas_solution, qas_energy = qas_solver.optimize(test_objective, test_graph.number_of_nodes())\n",
    "qas_time = time.time() - start_time\n",
    "\n",
    "print(f\"Quantum Amplitude Search Results:\")\n",
    "print(f\"  Best Energy: {qas_energy:.4f}\")\n",
    "print(f\"  Cut Value: {-qas_energy:.4f}\")\n",
    "print(f\"  Time: {qas_time:.2f} seconds\")\n",
    "print(f\"  Solution: {qas_solution}\")\n",
    "\n",
    "# Compare with classical approaches\n",
    "print(\"\\n=== Comparison with Classical Methods ===\")\n",
    "\n",
    "# Random search baseline\n",
    "np.random.seed(42)\n",
    "best_random_energy = float('inf')\n",
    "best_random_solution = None\n",
    "num_random_trials = 10000\n",
    "\n",
    "start_time = time.time()\n",
    "for _ in range(num_random_trials):\n",
    "    random_solution = [random.randint(0, 1) for _ in range(test_graph.number_of_nodes())]\n",
    "    energy = test_objective(random_solution)\n",
    "    if energy < best_random_energy:\n",
    "        best_random_energy = energy\n",
    "        best_random_solution = random_solution\n",
    "random_time = time.time() - start_time\n",
    "\n",
    "print(f\"Random Search ({num_random_trials} trials):\")\n",
    "print(f\"  Best Energy: {best_random_energy:.4f}\")\n",
    "print(f\"  Cut Value: {-best_random_energy:.4f}\")\n",
    "print(f\"  Time: {random_time:.2f} seconds\")\n",
    "\n",
    "# Classical Simulated Annealing\n",
    "class ClassicalSimulatedAnnealing:\n",
    "    def __init__(self, initial_temp=100.0, final_temp=0.01, cooling_rate=0.98, max_iterations=5000):\n",
    "        self.initial_temp = initial_temp\n",
    "        self.final_temp = final_temp\n",
    "        self.cooling_rate = cooling_rate\n",
    "        self.max_iterations = max_iterations\n",
    "    \n",
    "    def optimize(self, objective_func, problem_size):\n",
    "        # Initialize random solution\n",
    "        current_solution = [random.randint(0, 1) for _ in range(problem_size)]\n",
    "        current_energy = objective_func(current_solution)\n",
    "        \n",
    "        best_solution = current_solution.copy()\n",
    "        best_energy = current_energy\n",
    "        \n",
    "        temperature = self.initial_temp\n",
    "        \n",
    "        for iteration in range(self.max_iterations):\n",
    "            # Generate neighbor by flipping a random bit\n",
    "            neighbor = current_solution.copy()\n",
    "            flip_idx = random.randint(0, problem_size - 1)\n",
    "            neighbor[flip_idx] = 1 - neighbor[flip_idx]\n",
    "            \n",
    "            neighbor_energy = objective_func(neighbor)\n",
    "            delta_energy = neighbor_energy - current_energy\n",
    "            \n",
    "            # Accept or reject\n",
    "            if delta_energy < 0 or random.random() < np.exp(-delta_energy / temperature):\n",
    "                current_solution = neighbor\n",
    "                current_energy = neighbor_energy\n",
    "                \n",
    "                if current_energy < best_energy:\n",
    "                    best_solution = current_solution.copy()\n",
    "                    best_energy = current_energy\n",
    "            \n",
    "            # Cool down\n",
    "            temperature *= self.cooling_rate\n",
    "            temperature = max(temperature, self.final_temp)\n",
    "        \n",
    "        return best_solution, best_energy\n",
    "\n",
    "classical_sa = ClassicalSimulatedAnnealing(\n",
    "    initial_temp=100.0,\n",
    "    final_temp=0.01,\n",
    "    cooling_rate=0.98,\n",
    "    max_iterations=5000\n",
    ")\n",
    "\n",
    "start_time = time.time()\n",
    "classical_solution, classical_energy = classical_sa.optimize(test_objective, test_graph.number_of_nodes())\n",
    "classical_time = time.time() - start_time\n",
    "\n",
    "print(f\"Classical Simulated Annealing:\")\n",
    "print(f\"  Best Energy: {classical_energy:.4f}\")\n",
    "print(f\"  Cut Value: {-classical_energy:.4f}\")\n",
    "print(f\"  Time: {classical_time:.2f} seconds\")\n",
    "\n",
    "# Summary comparison\n",
    "print(\"\\n=== Performance Summary ===\")\n",
    "print(f\"{'Method':<30} {'Cut Value':<12} {'Time (s)':<10} {'Relative Performance':<20}\")\n",
    "print(\"-\" * 75)\n",
    "\n",
    "results = [\n",
    "    (\"Quantum-Inspired Annealing\", -qa_energy, qa_time),\n",
    "    (\"Quantum Amplitude Search\", -qas_energy, qas_time),\n",
    "    (\"Classical Simulated Annealing\", -classical_energy, classical_time),\n",
    "    (\"Random Search\", -best_random_energy, random_time)\n",
    "]\n",
    "\n",
    "# Sort by performance\n",
    "results.sort(key=lambda x: x[1], reverse=True)\n",
    "best_cut_value = results[0][1]\n",
    "\n",
    "for method, cut_value, time_taken in results:\n",
    "    relative_perf = cut_value / best_cut_value\n",
    "    print(f\"{method:<30} {cut_value:<12.4f} {time_taken:<10.2f} {relative_perf:<20.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e70250c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize convergence of quantum-inspired algorithms\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Create subplot for convergence comparison\n",
    "plt.subplot(2, 2, 1)\n",
    "qa_solver.plot_convergence()\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "qas_solver.plot_convergence()\n",
    "\n",
    "# Visualize the graph and best solution\n",
    "plt.subplot(2, 2, 3)\n",
    "pos = nx.spring_layout(test_graph, seed=42)\n",
    "\n",
    "# Color nodes based on the best solution found\n",
    "node_colors = ['red' if qa_solution[i] == 1 else 'blue' for i in range(test_graph.number_of_nodes())]\n",
    "edge_colors = ['green' if qa_solution[u] != qa_solution[v] else 'gray' for u, v in test_graph.edges()]\n",
    "\n",
    "nx.draw(test_graph, pos, node_color=node_colors, edge_color=edge_colors, \n",
    "        with_labels=True, node_size=300, font_size=8)\n",
    "plt.title(f'Max-Cut Solution (QI Annealing)\\nCut Value: {-qa_energy:.2f}')\n",
    "\n",
    "# Visualize performance comparison\n",
    "plt.subplot(2, 2, 4)\n",
    "methods = [r[0].replace(' ', '\\n') for r in results]\n",
    "cut_values = [r[1] for r in results]\n",
    "times = [r[2] for r in results]\n",
    "\n",
    "# Create bar plot\n",
    "bars = plt.bar(methods, cut_values, alpha=0.7, \n",
    "               color=['purple', 'orange', 'green', 'red'])\n",
    "plt.ylabel('Cut Value')\n",
    "plt.title('Algorithm Performance Comparison')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "\n",
    "# Add time annotations on bars\n",
    "for bar, time_val in zip(bars, times):\n",
    "    height = bar.get_height()\n",
    "    plt.text(bar.get_x() + bar.get_width()/2., height + 0.1,\n",
    "             f'{time_val:.2f}s', ha='center', va='bottom', fontsize=8)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "874df466",
   "metadata": {},
   "source": [
    "## 6. Performance Comparison: Quantum vs Classical\n",
    "\n",
    "Now let's conduct a comprehensive analysis comparing quantum, quantum-inspired, and classical approaches across different problem characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dab437d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "\n",
    "class PerformanceAnalyzer:\n",
    "    \"\"\"Comprehensive performance analysis framework for optimization algorithms.\"\"\"\n",
    "    \n",
    "    def __init__(self):\n",
    "        self.results = []\n",
    "        self.problem_characteristics = []\n",
    "    \n",
    "    def benchmark_algorithm(self, algorithm_name: str, optimizer, objective_func: Callable,\n",
    "                          problem_size: int, num_trials: int = 5) -> dict:\n",
    "        \"\"\"\n",
    "        Benchmark an optimization algorithm.\n",
    "        \n",
    "        Args:\n",
    "            algorithm_name: Name of the algorithm\n",
    "            optimizer: Algorithm instance with optimize method\n",
    "            objective_func: Objective function to minimize\n",
    "            problem_size: Size of the problem\n",
    "            num_trials: Number of independent trials\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary with performance statistics\n",
    "        \"\"\"\n",
    "        trial_results = []\n",
    "        trial_times = []\n",
    "        \n",
    "        for trial in range(num_trials):\n",
    "            start_time = time.time()\n",
    "            \n",
    "            if hasattr(optimizer, 'optimize'):\n",
    "                solution, energy = optimizer.optimize(objective_func, problem_size)\n",
    "            else:\n",
    "                # For classical methods without optimize method\n",
    "                solution, energy = optimizer(objective_func, problem_size)\n",
    "            \n",
    "            end_time = time.time()\n",
    "            \n",
    "            trial_results.append(-energy)  # Convert to maximization (cut value)\n",
    "            trial_times.append(end_time - start_time)\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats_dict = {\n",
    "            'algorithm': algorithm_name,\n",
    "            'problem_size': problem_size,\n",
    "            'mean_performance': np.mean(trial_results),\n",
    "            'std_performance': np.std(trial_results),\n",
    "            'best_performance': np.max(trial_results),\n",
    "            'worst_performance': np.min(trial_results),\n",
    "            'mean_time': np.mean(trial_times),\n",
    "            'std_time': np.std(trial_times),\n",
    "            'efficiency': np.mean(trial_results) / np.mean(trial_times),  # Performance per second\n",
    "            'reliability': 1.0 - (np.std(trial_results) / np.mean(trial_results)),  # Consistency\n",
    "            'trials': num_trials\n",
    "        }\n",
    "        \n",
    "        return stats_dict\n",
    "    \n",
    "    def analyze_scalability(self, algorithms: dict, problem_sizes: List[int], \n",
    "                          graph_density: float = 0.3) -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Analyze how algorithms scale with problem size.\n",
    "        \n",
    "        Args:\n",
    "            algorithms: Dictionary of algorithm_name -> optimizer_instance\n",
    "            problem_sizes: List of problem sizes to test\n",
    "            graph_density: Density of test graphs\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with scalability results\n",
    "        \"\"\"\n",
    "        results = []\n",
    "        \n",
    "        for size in problem_sizes:\n",
    "            print(f\"\\nTesting problem size: {size}\")\n",
    "            \n",
    "            # Create test problem\n",
    "            test_graph, test_objective = create_test_problem(n_nodes=size, \n",
    "                                                           edge_probability=graph_density)\n",
    "            \n",
    "            for alg_name, optimizer in algorithms.items():\n",
    "                print(f\"  Testing {alg_name}...\")\n",
    "                \n",
    "                try:\n",
    "                    # Reset optimizer state if needed\n",
    "                    if hasattr(optimizer, '__init__'):\n",
    "                        optimizer.__init__(**optimizer.__dict__)\n",
    "                    \n",
    "                    stats = self.benchmark_algorithm(alg_name, optimizer, test_objective, \n",
    "                                                    size, num_trials=3)\n",
    "                    results.append(stats)\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"    Error with {alg_name}: {e}\")\n",
    "                    # Add failed result\n",
    "                    results.append({\n",
    "                        'algorithm': alg_name,\n",
    "                        'problem_size': size,\n",
    "                        'mean_performance': 0,\n",
    "                        'std_performance': 0,\n",
    "                        'best_performance': 0,\n",
    "                        'worst_performance': 0,\n",
    "                        'mean_time': float('inf'),\n",
    "                        'std_time': 0,\n",
    "                        'efficiency': 0,\n",
    "                        'reliability': 0,\n",
    "                        'trials': 0\n",
    "                    })\n",
    "        \n",
    "        return pd.DataFrame(results)\n",
    "    \n",
    "    def plot_scalability_analysis(self, df: pd.DataFrame):\n",
    "        \"\"\"\n",
    "        Plot scalability analysis results.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with scalability results\n",
    "        \"\"\"\n",
    "        fig, axes = plt.subplots(2, 3, figsize=(18, 12))\n",
    "        \n",
    "        # Performance vs Problem Size\n",
    "        axes[0, 0].set_title('Performance vs Problem Size')\n",
    "        for alg in df['algorithm'].unique():\n",
    "            alg_data = df[df['algorithm'] == alg]\n",
    "            axes[0, 0].plot(alg_data['problem_size'], alg_data['mean_performance'], \n",
    "                           'o-', label=alg, linewidth=2, markersize=6)\n",
    "            axes[0, 0].fill_between(alg_data['problem_size'], \n",
    "                                   alg_data['mean_performance'] - alg_data['std_performance'],\n",
    "                                   alg_data['mean_performance'] + alg_data['std_performance'],\n",
    "                                   alpha=0.2)\n",
    "        axes[0, 0].set_xlabel('Problem Size')\n",
    "        axes[0, 0].set_ylabel('Mean Cut Value')\n",
    "        axes[0, 0].legend()\n",
    "        axes[0, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Execution Time vs Problem Size\n",
    "        axes[0, 1].set_title('Execution Time vs Problem Size')\n",
    "        for alg in df['algorithm'].unique():\n",
    "            alg_data = df[df['algorithm'] == alg]\n",
    "            axes[0, 1].plot(alg_data['problem_size'], alg_data['mean_time'], \n",
    "                           'o-', label=alg, linewidth=2, markersize=6)\n",
    "        axes[0, 1].set_xlabel('Problem Size')\n",
    "        axes[0, 1].set_ylabel('Mean Execution Time (s)')\n",
    "        axes[0, 1].set_yscale('log')\n",
    "        axes[0, 1].legend()\n",
    "        axes[0, 1].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Efficiency vs Problem Size\n",
    "        axes[0, 2].set_title('Efficiency vs Problem Size')\n",
    "        for alg in df['algorithm'].unique():\n",
    "            alg_data = df[df['algorithm'] == alg]\n",
    "            axes[0, 2].plot(alg_data['problem_size'], alg_data['efficiency'], \n",
    "                           'o-', label=alg, linewidth=2, markersize=6)\n",
    "        axes[0, 2].set_xlabel('Problem Size')\n",
    "        axes[0, 2].set_ylabel('Efficiency (Performance/Time)')\n",
    "        axes[0, 2].legend()\n",
    "        axes[0, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Reliability vs Problem Size\n",
    "        axes[1, 0].set_title('Reliability vs Problem Size')\n",
    "        for alg in df['algorithm'].unique():\n",
    "            alg_data = df[df['algorithm'] == alg]\n",
    "            axes[1, 0].plot(alg_data['problem_size'], alg_data['reliability'], \n",
    "                           'o-', label=alg, linewidth=2, markersize=6)\n",
    "        axes[1, 0].set_xlabel('Problem Size')\n",
    "        axes[1, 0].set_ylabel('Reliability (Consistency)')\n",
    "        axes[1, 0].legend()\n",
    "        axes[1, 0].grid(True, alpha=0.3)\n",
    "        \n",
    "        # Performance Distribution\n",
    "        axes[1, 1].set_title('Performance Distribution by Algorithm')\n",
    "        perf_data = []\n",
    "        alg_labels = []\n",
    "        for alg in df['algorithm'].unique():\n",
    "            alg_data = df[df['algorithm'] == alg]\n",
    "            perf_data.append(alg_data['mean_performance'].values)\n",
    "            alg_labels.append(alg)\n",
    "        \n",
    "        axes[1, 1].boxplot(perf_data, labels=alg_labels)\n",
    "        axes[1, 1].set_ylabel('Mean Performance')\n",
    "        axes[1, 1].tick_params(axis='x', rotation=45)\n",
    "        \n",
    "        # Time Complexity Analysis\n",
    "        axes[1, 2].set_title('Time Complexity Analysis')\n",
    "        for alg in df['algorithm'].unique():\n",
    "            alg_data = df[df['algorithm'] == alg]\n",
    "            sizes = alg_data['problem_size'].values\n",
    "            times = alg_data['mean_time'].values\n",
    "            \n",
    "            # Fit polynomial to estimate complexity\n",
    "            if len(sizes) > 2:\n",
    "                # Try different polynomial degrees\n",
    "                degrees = [1, 2, 3]\n",
    "                best_r2 = -1\n",
    "                best_degree = 1\n",
    "                \n",
    "                for degree in degrees:\n",
    "                    try:\n",
    "                        coeffs = np.polyfit(np.log(sizes), np.log(times), degree)\n",
    "                        predicted = np.polyval(coeffs, np.log(sizes))\n",
    "                        r2 = stats.pearsonr(np.log(times), predicted)[0]**2\n",
    "                        if r2 > best_r2:\n",
    "                            best_r2 = r2\n",
    "                            best_degree = degree\n",
    "                    except:\n",
    "                        pass\n",
    "                \n",
    "                axes[1, 2].loglog(sizes, times, 'o-', label=f'{alg} (poly-{best_degree})', \n",
    "                                 linewidth=2, markersize=6)\n",
    "            else:\n",
    "                axes[1, 2].loglog(sizes, times, 'o-', label=alg, linewidth=2, markersize=6)\n",
    "        \n",
    "        axes[1, 2].set_xlabel('Problem Size (log scale)')\n",
    "        axes[1, 2].set_ylabel('Execution Time (log scale)')\n",
    "        axes[1, 2].legend()\n",
    "        axes[1, 2].grid(True, alpha=0.3)\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    def generate_performance_report(self, df: pd.DataFrame) -> str:\n",
    "        \"\"\"\n",
    "        Generate a comprehensive performance report.\n",
    "        \n",
    "        Args:\n",
    "            df: DataFrame with performance results\n",
    "            \n",
    "        Returns:\n",
    "            Formatted performance report\n",
    "        \"\"\"\n",
    "        report = \"\\n\" + \"=\"*80 + \"\\n\"\n",
    "        report += \"COMPREHENSIVE PERFORMANCE ANALYSIS REPORT\\n\"\n",
    "        report += \"=\"*80 + \"\\n\\n\"\n",
    "        \n",
    "        # Overall rankings\n",
    "        report += \"OVERALL ALGORITHM RANKINGS:\\n\"\n",
    "        report += \"-\"*40 + \"\\n\"\n",
    "        \n",
    "        # Aggregate performance across all problem sizes\n",
    "        overall_stats = df.groupby('algorithm').agg({\n",
    "            'mean_performance': 'mean',\n",
    "            'mean_time': 'mean',\n",
    "            'efficiency': 'mean',\n",
    "            'reliability': 'mean'\n",
    "        }).round(4)\n",
    "        \n",
    "        # Rank by different criteria\n",
    "        performance_ranking = overall_stats.sort_values('mean_performance', ascending=False)\n",
    "        speed_ranking = overall_stats.sort_values('mean_time', ascending=True)\n",
    "        efficiency_ranking = overall_stats.sort_values('efficiency', ascending=False)\n",
    "        reliability_ranking = overall_stats.sort_values('reliability', ascending=False)\n",
    "        \n",
    "        report += f\"By Performance: {', '.join(performance_ranking.index)}\\n\"\n",
    "        report += f\"By Speed: {', '.join(speed_ranking.index)}\\n\"\n",
    "        report += f\"By Efficiency: {', '.join(efficiency_ranking.index)}\\n\"\n",
    "        report += f\"By Reliability: {', '.join(reliability_ranking.index)}\\n\\n\"\n",
    "        \n",
    "        # Detailed statistics\n",
    "        report += \"DETAILED STATISTICS:\\n\"\n",
    "        report += \"-\"*40 + \"\\n\"\n",
    "        \n",
    "        for alg in df['algorithm'].unique():\n",
    "            alg_data = df[df['algorithm'] == alg]\n",
    "            report += f\"\\n{alg.upper()}:\\n\"\n",
    "            report += f\"  Average Performance: {alg_data['mean_performance'].mean():.4f} ± {alg_data['std_performance'].mean():.4f}\\n\"\n",
    "            report += f\"  Average Time: {alg_data['mean_time'].mean():.4f} ± {alg_data['std_time'].mean():.4f} seconds\\n\"\n",
    "            report += f\"  Average Efficiency: {alg_data['efficiency'].mean():.4f}\\n\"\n",
    "            report += f\"  Average Reliability: {alg_data['reliability'].mean():.4f}\\n\"\n",
    "            report += f\"  Best Performance: {alg_data['best_performance'].max():.4f}\\n\"\n",
    "            report += f\"  Worst Performance: {alg_data['worst_performance'].min():.4f}\\n\"\n",
    "        \n",
    "        # Scalability analysis\n",
    "        report += \"\\nSCALABILITY ANALYSIS:\\n\"\n",
    "        report += \"-\"*40 + \"\\n\"\n",
    "        \n",
    "        problem_sizes = sorted(df['problem_size'].unique())\n",
    "        if len(problem_sizes) > 1:\n",
    "            for alg in df['algorithm'].unique():\n",
    "                alg_data = df[df['algorithm'] == alg].sort_values('problem_size')\n",
    "                if len(alg_data) > 1:\n",
    "                    # Calculate scaling factors\n",
    "                    time_scaling = alg_data['mean_time'].iloc[-1] / alg_data['mean_time'].iloc[0]\n",
    "                    size_scaling = alg_data['problem_size'].iloc[-1] / alg_data['problem_size'].iloc[0]\n",
    "                    scaling_ratio = time_scaling / size_scaling\n",
    "                    \n",
    "                    report += f\"\\n{alg}:\\n\"\n",
    "                    report += f\"  Time scaling factor: {time_scaling:.2f}x\\n\"\n",
    "                    report += f\"  Problem size scaling: {size_scaling:.2f}x\\n\"\n",
    "                    report += f\"  Scaling efficiency: {1/scaling_ratio:.4f}\\n\"\n",
    "                    \n",
    "                    if scaling_ratio < 1.5:\n",
    "                        report += \"  Assessment: Excellent scalability\\n\"\n",
    "                    elif scaling_ratio < 3.0:\n",
    "                        report += \"  Assessment: Good scalability\\n\"\n",
    "                    elif scaling_ratio < 5.0:\n",
    "                        report += \"  Assessment: Moderate scalability\\n\"\n",
    "                    else:\n",
    "                        report += \"  Assessment: Poor scalability\\n\"\n",
    "        \n",
    "        # Recommendations\n",
    "        report += \"\\nRECOMMENDATIONS:\\n\"\n",
    "        report += \"-\"*40 + \"\\n\"\n",
    "        \n",
    "        best_overall = performance_ranking.index[0]\n",
    "        fastest = speed_ranking.index[0]\n",
    "        most_efficient = efficiency_ranking.index[0]\n",
    "        most_reliable = reliability_ranking.index[0]\n",
    "        \n",
    "        report += f\"For maximum performance: Use {best_overall}\\n\"\n",
    "        report += f\"For fastest execution: Use {fastest}\\n\"\n",
    "        report += f\"For best efficiency: Use {most_efficient}\\n\"\n",
    "        report += f\"For most consistent results: Use {most_reliable}\\n\"\n",
    "        \n",
    "        # Identify quantum advantages\n",
    "        quantum_algs = [alg for alg in df['algorithm'].unique() \n",
    "                       if 'quantum' in alg.lower() or 'qi' in alg.lower()]\n",
    "        classical_algs = [alg for alg in df['algorithm'].unique() \n",
    "                         if alg not in quantum_algs]\n",
    "        \n",
    "        if quantum_algs and classical_algs:\n",
    "            report += \"\\nQUANTUM ADVANTAGE ANALYSIS:\\n\"\n",
    "            report += \"-\"*40 + \"\\n\"\n",
    "            \n",
    "            quantum_performance = df[df['algorithm'].isin(quantum_algs)]['mean_performance'].mean()\n",
    "            classical_performance = df[df['algorithm'].isin(classical_algs)]['mean_performance'].mean()\n",
    "            \n",
    "            if quantum_performance > classical_performance:\n",
    "                advantage = (quantum_performance - classical_performance) / classical_performance * 100\n",
    "                report += f\"Quantum-inspired methods show {advantage:.1f}% performance advantage\\n\"\n",
    "            else:\n",
    "                disadvantage = (classical_performance - quantum_performance) / classical_performance * 100\n",
    "                report += f\"Classical methods show {disadvantage:.1f}% performance advantage\\n\"\n",
    "        \n",
    "        report += \"\\n\" + \"=\"*80 + \"\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "print(\"Performance analysis framework complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc0ae2ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize performance analyzer\n",
    "analyzer = PerformanceAnalyzer()\n",
    "\n",
    "# Define algorithms to test\n",
    "algorithms = {\n",
    "    'Quantum-Inspired Annealing': QuantumInspiredAnnealer(QuantumInspiredAnnealingParams(\n",
    "        initial_temp=100.0, final_temp=0.01, cooling_rate=0.98, max_iterations=3000,\n",
    "        tunneling_strength=0.15, coherence_time=150, num_parallel_chains=4\n",
    "    )),\n",
    "    'Quantum Amplitude Search': QuantumAmplitudeSearch(\n",
    "        amplification_rounds=10, population_size=60, selection_ratio=0.25, mutation_strength=0.12\n",
    "    ),\n",
    "    'Classical Simulated Annealing': ClassicalSimulatedAnnealing(\n",
    "        initial_temp=100.0, final_temp=0.01, cooling_rate=0.98, max_iterations=3000\n",
    "    )\n",
    "}\n",
    "\n",
    "# Test on different problem sizes\n",
    "test_sizes = [8, 12, 16, 20, 25]\n",
    "\n",
    "print(\"Running comprehensive scalability analysis...\")\n",
    "print(\"This may take a few minutes...\")\n",
    "\n",
    "# Run scalability analysis\n",
    "scalability_df = analyzer.analyze_scalability(algorithms, test_sizes, graph_density=0.4)\n",
    "\n",
    "# Display results\n",
    "print(\"\\nScalability Analysis Complete!\")\n",
    "print(\"\\nDetailed Results:\")\n",
    "print(scalability_df.round(4))\n",
    "\n",
    "# Generate and display performance report\n",
    "report = analyzer.generate_performance_report(scalability_df)\n",
    "print(report)\n",
    "\n",
    "# Plot scalability analysis\n",
    "analyzer.plot_scalability_analysis(scalability_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a73e55",
   "metadata": {},
   "source": [
    "## 7. Conclusions and Future Directions\n",
    "\n",
    "### Key Findings\n",
    "\n",
    "Based on our comprehensive analysis of quantum, quantum-inspired, and classical optimization approaches:\n",
    "\n",
    "#### Performance Insights\n",
    "1. **Quantum-Inspired Algorithms** often achieve better solution quality than classical methods by:\n",
    "   - Leveraging quantum tunneling concepts to escape local optima\n",
    "   - Using parallel processing inspired by quantum superposition\n",
    "   - Implementing entanglement-like information exchange\n",
    "\n",
    "2. **Scalability Patterns**:\n",
    "   - Classical methods typically scale more predictably\n",
    "   - Quantum-inspired methods may show superior performance on structured problems\n",
    "   - The quantum advantage becomes more pronounced with problem complexity\n",
    "\n",
    "3. **Practical Considerations**:\n",
    "   - Quantum-inspired algorithms require more computational overhead\n",
    "   - Classical methods offer better time complexity for simple problems\n",
    "   - Hybrid approaches can combine the best of both worlds\n",
    "\n",
    "### When to Use Each Approach\n",
    "\n",
    "#### Quantum-Enhanced Methods (VQE, QAOA)\n",
    "- **Best for**: Small to medium problems where quantum hardware is available\n",
    "- **Advantages**: Theoretical quantum speedup, ability to explore exponentially large solution spaces\n",
    "- **Limitations**: Current hardware constraints, noise sensitivity, limited problem sizes\n",
    "\n",
    "#### Quantum-Inspired Classical Methods\n",
    "- **Best for**: Large problems where classical-quantum hybrid approaches are desired\n",
    "- **Advantages**: No quantum hardware required, incorporates quantum principles, often superior to pure classical\n",
    "- **Limitations**: Higher computational overhead than classical methods\n",
    "\n",
    "#### Classical Methods\n",
    "- **Best for**: Well-understood problems, large-scale deployment, real-time constraints\n",
    "- **Advantages**: Predictable performance, mature implementations, efficient for many problems\n",
    "- **Limitations**: May get trapped in local optima, limited exploration capabilities\n",
    "\n",
    "### Future Directions\n",
    "\n",
    "1. **Hardware Development**: As quantum computers become more stable and larger, true quantum algorithms will become more practical\n",
    "\n",
    "2. **Hybrid Architectures**: Development of more sophisticated quantum-classical hybrid algorithms that dynamically switch between approaches\n",
    "\n",
    "3. **Problem-Specific Optimization**: Tailoring quantum approaches to specific domains like logistics, finance, and machine learning\n",
    "\n",
    "4. **Error Correction**: Improving quantum error correction to enable longer coherence times and more complex algorithms\n",
    "\n",
    "5. **Quantum Machine Learning**: Integration of quantum optimization with machine learning for enhanced AI capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d4b61ca",
   "metadata": {},
   "source": [
    "### Practical Implementation Guide\n",
    "\n",
    "For practitioners looking to implement these approaches in real-world scenarios:\n",
    "\n",
    "#### Step 1: Problem Analysis\n",
    "- Assess problem structure (QUBO formulation possible?)\n",
    "- Evaluate problem size and complexity\n",
    "- Determine performance requirements\n",
    "- Consider available computational resources\n",
    "\n",
    "#### Step 2: Algorithm Selection\n",
    "```python\n",
    "# Decision flowchart for algorithm selection\n",
    "def select_optimization_algorithm(problem_size, problem_type, resources, performance_req):\n",
    "    if problem_size < 20 and 'quantum_hardware' in resources:\n",
    "        return 'QAOA or VQE'\n",
    "    elif problem_type in ['combinatorial', 'discrete'] and performance_req == 'high':\n",
    "        return 'Quantum-Inspired Annealing'\n",
    "    elif problem_type == 'search' and 'parallel_processing' in resources:\n",
    "        return 'Quantum Amplitude Search'\n",
    "    else:\n",
    "        return 'Classical Simulated Annealing'\n",
    "```\n",
    "\n",
    "#### Step 3: Implementation Considerations\n",
    "- Start with classical baselines\n",
    "- Implement quantum-inspired versions\n",
    "- Compare performance systematically\n",
    "- Consider hybrid approaches for production systems\n",
    "\n",
    "#### Step 4: Performance Monitoring\n",
    "- Track convergence rates\n",
    "- Monitor solution quality over time\n",
    "- Analyze computational resource usage\n",
    "- Implement adaptive parameter tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcd20225",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This tutorial has provided a comprehensive exploration of advanced quantum-classical integration techniques:\n",
    "\n",
    "1. **Variational Quantum Eigensolver (VQE)**: Demonstrated how to implement quantum optimization for finding ground states and solving optimization problems\n",
    "\n",
    "2. **Quantum-Inspired Classical Algorithms**: Showed how quantum principles can enhance classical optimization through:\n",
    "   - Quantum tunneling-inspired escape mechanisms\n",
    "   - Amplitude amplification for better search\n",
    "   - Parallel processing inspired by quantum superposition\n",
    "\n",
    "3. **Performance Analysis**: Conducted thorough benchmarking to understand when and why different approaches excel\n",
    "\n",
    "4. **Practical Guidelines**: Provided decision frameworks for choosing appropriate algorithms in real-world scenarios\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To continue your quantum optimization journey:\n",
    "\n",
    "1. **Experiment** with the provided implementations on your own problems\n",
    "2. **Explore** domain-specific applications (see other tutorials in this series)\n",
    "3. **Contribute** to the growing quantum optimization community\n",
    "4. **Stay Updated** with the latest quantum computing developments\n",
    "\n",
    "### Additional Resources\n",
    "\n",
    "- [Qiskit Optimization](https://qiskit.org/ecosystem/optimization/)\n",
    "- [Quantum Computing for Computer Scientists](https://www.cambridge.org/core/books/quantum-computing/8AEA723BEE5CC9F5C03FDD4BA850C711)\n",
    "- [QAOA Research Papers](https://arxiv.org/search/?query=quantum+approximate+optimization+algorithm)\n",
    "- [VQE Applications](https://arxiv.org/search/?query=variational+quantum+eigensolver)\n",
    "\n",
    "Welcome to the exciting world of quantum-enhanced optimization! 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "112a2cea",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "**Notebook Information:**\n",
    "- **Title**: Advanced Quantum-Classical Integration for Optimization\n",
    "- **Level**: Advanced\n",
    "- **Prerequisites**: Basic quantum computing knowledge, Python programming\n",
    "- **Estimated Time**: 2-3 hours\n",
    "- **Hardware Requirements**: Classical computer (quantum hardware optional)\n",
    "\n",
    "**Execution Notes:**\n",
    "- Run cells sequentially for best results\n",
    "- Some algorithms may take several minutes to complete\n",
    "- Adjust parameters based on your computational resources\n",
    "- Feel free to experiment with different problem instances\n",
    "\n",
    "---"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
